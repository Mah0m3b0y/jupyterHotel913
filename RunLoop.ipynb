{"cells":[{"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"09d10752-6c53-4ad4-a48a-61dc4b8ead4e","showTitle":false,"title":""}},"cell_type":"markdown","source":"# Setup, Inits and Function Repository"},{"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"b92aa736-a8c2-4736-b202-5cb24a7bbc42","showTitle":false,"title":""}},"cell_type":"markdown","source":"## 1. Imports"},{"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"0a6b8a22-5291-4dfa-a559-24f556b2cc40","showTitle":false,"title":""},"trusted":false},"cell_type":"code","source":"%run \"./SAP_FDD_Env_and_Utils\"","execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}},{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">WARNING: v1.3.0 is deprecated. End of support is 04-01-2023. Using databricks_v2 is suggested.\nDatabricks SDK v1.3.0 - successfully loaded\n</div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\">WARNING: v1.3.0 is deprecated. End of support is 04-01-2023. Using databricks_v2 is suggested.\nDatabricks SDK v1.3.0 - successfully loaded\n</div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}},{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}},{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}},{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">WARNING! engine is not default parameter.\n                    engine was transferred to model_kwargs.\n                    Please confirm that engine is what you intended.\n</div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\">WARNING! engine is not default parameter.\n                    engine was transferred to model_kwargs.\n                    Please confirm that engine is what you intended.\n</div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}},{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}},{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}},{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}},{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}},{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}},{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}},{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}},{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}},{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}},{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}},{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}},{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}},{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}},{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}},{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}},{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}},{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}},{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}},{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}},{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}},{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}},{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}},{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}},{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}},{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}}]},{"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"3d01f09a-6e9c-426b-9d8e-203ee553f134","showTitle":false,"title":""},"trusted":false},"cell_type":"code","source":"%run \"./SAP_FDD_Core\"","execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}},{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}},{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}},{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}},{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}},{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}},{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}}]},{"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"ebd7278b-2cd8-478a-b734-fd5fbaaa8d1d","showTitle":false,"title":""},"trusted":false},"cell_type":"code","source":"%run \"./SAP_FDD_Indexing\"","execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}},{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}},{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}},{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}},{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}},{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}},{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}},{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}},{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}},{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}},{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}},{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}},{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}},{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}},{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}}]},{"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"d4ed14c9-0226-48aa-a48d-d113fa569cb0","showTitle":false,"title":""}},"cell_type":"markdown","source":"# Workflow for multiple documents"},{"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"c7f32aa5-42ab-49e1-8193-c700ff59fd1c","showTitle":false,"title":""}},"cell_type":"markdown","source":"## 1. Read input documents (requirements list & mapping to templates)"},{"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"4ec6bfef-1d71-4677-a0ab-92288a1ca217","showTitle":false,"title":""},"trusted":false},"cell_type":"code","source":"## Specify paths for input files\nfilename_mapping = \"Mapping Template.xlsx\"\nfilename_requirements = \"Codes_mapping.xlsx\"\nfilename_transcripts = \"cleansed_transcript_new1.txt\"\n\nfolder_input = \"/tmp/Input_SAP/\" \nfolder_main = \"/tmp/SAP\"","execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}}]},{"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"eac253c9-7ed0-4034-bb0e-1b74d23d254c","showTitle":false,"title":""},"trusted":false},"cell_type":"code","source":"# Copy cleansed transcripts from workbench - only needed on cluster restart\ndb_ws.CopyFileFromWorkbench(DatabricksFolder=\"file:\"+folder_input,filename=filename_transcripts)","execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}}]},{"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"98eaf3c3-29ce-4162-b3b8-f407831ec776","showTitle":false,"title":""},"trusted":false},"cell_type":"code","source":"## Parse requirements\ndf_requirements_clean = get_df_requirements(folder_input, filename_requirements)\n## Parse Mapping file\ndf_mapping = get_df_mapping(folder_input, filename_mapping)","execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}}]},{"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"3477b87c-bb72-4b9b-b401-3f85148e2d3f","showTitle":false,"title":""}},"cell_type":"markdown","source":"##2. Load stored indexes"},{"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"b168f539-2f13-401d-9fdc-60a3f7ba8d11","showTitle":false,"title":""},"trusted":false},"cell_type":"code","source":"### Change these index names / locations whenever a new index version has been created!\n\n# FSD INDEXES\nFSD_INDEX_LATEST_VERSION_FAISS = \"indexstore_FSD_OpenAI_v1_chunked.pkl\"\nFSD_INDEX_LATEST_VERSION_WHOOSH = \"/tmp/SAP/index_fsd_whoosh\"\nFSD_INDEX_LATEST_VERSION_ACS = \"uc-sap-index-fsd\"\n\n# BPD INDEXES\nBPD_INDEX_LATEST_VERSION_FAISS = \"indexstore_BPD_OpenAI_v3_chunked.pkl\"\nBPD_INDEX_LATEST_VERSION_WHOOSH = \"/tmp/SAP/index_bpd_whoosh\"\nBPD_INDEX_LATEST_VERSION_ACS = \"uc-sap-index-bpd\"\n\n# TRANSCRIPTS INDEXES\nTRANSCRIPTS_INDEX_LATEST_VERSION_FAISS = \"indexstore_Transcripts_OpenAI_v6_chunked.pkl\"\nTRANSCRIPTS_INDEX_LATEST_VERSION_WHOOSH = \"/tmp/SAP/index_transcripts_whoosh\"\nTRANSCRIPTS_INDEX_LATEST_VERSION_ACS = \"uc-sap-index-transcripts\"\n\n# IMAGES INDEXES\nIMAGES_INDEX_LATEST_VERSION_ACS = \"uc-sap-index-images\"","execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}}]},{"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"e81b1435-914f-42f9-9e8c-4aa2ebe3659b","showTitle":false,"title":""},"trusted":false},"cell_type":"code","source":"### Load all index types for all input sources (loading is efficient, should only take a few seconds)\n\n# FSDs\nindex_fsd_faiss, db_fsd_faiss = read_index_func(folder_main, FSD_INDEX_LATEST_VERSION_FAISS, llm=llm, chain_type=\"stuff\")\n# # index_fsd_whoosh = DocumentIndexWhoosh().load(FSD_INDEX_LATEST_VERSION_WHOOSH)\n# index_fsd_combined = CombinedIndex(db_fsd_faiss, index_fsd_whoosh)\nindex_fsd_acs = DocumentIndexACS_v2(ACS_ENDPOINT, ACS_KEY, FSD_INDEX_LATEST_VERSION_ACS).load()\n\n# BPDs\nindex_bpd_faiss, db_bpd_faiss = read_index_func(folder_main, BPD_INDEX_LATEST_VERSION_FAISS, llm=llm, chain_type=\"stuff\")\n# index_bpd_whoosh = DocumentIndexWhoosh().load(BPD_INDEX_LATEST_VERSION_WHOOSH)\n# index_bpd_combined = CombinedIndex(db_bpd_faiss, index_bpd_whoosh)\nindex_bpd_acs = DocumentIndexACS_v2(ACS_ENDPOINT, ACS_KEY, BPD_INDEX_LATEST_VERSION_ACS).load()\n\n# Transcripts\nindex_transcripts_faiss, db_transcripts_faiss = read_index_func(folder_main, TRANSCRIPTS_INDEX_LATEST_VERSION_FAISS, llm=llm, chain_type=\"stuff\")\n# index_transcripts_whoosh = DocumentIndexWhoosh().load(TRANSCRIPTS_INDEX_LATEST_VERSION_WHOOSH)\n# index_transcripts_combined = CombinedIndex(db_transcripts_faiss, index_transcripts_whoosh)\nindex_transcripts_acs = DocumentIndexACS_v2(ACS_ENDPOINT, ACS_KEY, TRANSCRIPTS_INDEX_LATEST_VERSION_ACS).load()\n\n# Image Processing\nindex_images_acs = DocumentIndexACS_v2(ACS_ENDPOINT, ACS_KEY, IMAGES_INDEX_LATEST_VERSION_ACS).load()","execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}}]},{"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"d2949e8f-f011-4a65-922d-ac4b0afabf59","showTitle":false,"title":""},"trusted":false},"cell_type":"code","source":"### Check the status for all index types and input sources - 'True' means the index is usable, 'False' indicates errors\n\ntest_query = \"Test\"\n\n# print(f\"FSD - FAISS Status: {len(db_fsd_faiss.similarity_search(test_query)) != 0}\")\n# print(f\"FSD - Whoosh Status: {len(list(index_fsd_whoosh.search(test_query))) != 0}\")\n# print(f\"FSD - Combined Status: {len(index_fsd_combined.search(test_query)) != 0}\")\nprint(f\"FSD - ACS Status: {len(index_fsd_acs.search(test_query)) != 0}\")\n\n# print(f\"BPD - FAISS Status: {len(db_bpd_faiss.similarity_search(test_query)) != 0}\")\n# print(f\"BPD - Whoosh Status: {len(list(index_bpd_whoosh.search(test_query))) != 0}\")\n# print(f\"BPD - Combined Status: {len(index_bpd_combined.search(test_query)) != 0}\")\nprint(f\"BPD - ACS Status: {len(index_bpd_acs.search(test_query)) != 0}\")\n\n# print(f\"Transcripts - FAISS Status: {len(db_transcripts_faiss.similarity_search(test_query)) != 0}\")\n# print(f\"Transcripts - Whoosh Status: {len(list(index_transcripts_whoosh.search(test_query))) != 0}\")\n# print(f\"Transcripts - Combined Status: {len(index_transcripts_combined.search(test_query)) != 0}\")\nprint(f\"Transcripts - ACS Status: {len(index_transcripts_acs.search(test_query)) != 0}\")\n\nprint(f\"Images - ACS Status: {len(index_images_acs.search(test_query)) != 0}\")","execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">FSD - ACS Status: True\nBPD - ACS Status: True\nTranscripts - ACS Status: True\nImages - ACS Status: False\n</div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\">FSD - ACS Status: True\nBPD - ACS Status: True\nTranscripts - ACS Status: True\nImages - ACS Status: False\n</div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}}]},{"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"c61a6bf2-45d7-4dd1-b905-114010654d7f","showTitle":false,"title":""},"trusted":false},"cell_type":"code","source":"### Choose which index types to use for each input source\n\nindex_fsd = index_fsd_acs\nindex_bpd = index_bpd_acs\nindex_transcripts = index_transcripts_acs\nindex_images = index_images_acs","execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}}]},{"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"83ad8247-2686-45f1-a4d8-8199108c957d","showTitle":false,"title":""},"trusted":false},"cell_type":"code","source":"print(index_fsd)","execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">&lt;__main__.DocumentIndexACS_v2 object at 0x7ff0c6626280&gt;\n</div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\">&lt;__main__.DocumentIndexACS_v2 object at 0x7ff0c6626280&gt;\n</div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}}]},{"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"bc3e91bb-8721-493f-a8a5-b4ff30c3b9ee","showTitle":false,"title":""},"trusted":false},"cell_type":"code","source":"# knowledge_base = read_knowledge_base(\"/tmp/SAP/\", KNOWLEDGE_BASE_LATEST_VERSION)","execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}}]},{"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"c67219be-1a29-4b6a-9b25-2fef36fe30ae","showTitle":false,"title":""}},"cell_type":"markdown","source":"## 3. Select requirements to be populated"},{"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"3d25c92a-c424-47f5-94d7-cf9953b7a2e4","showTitle":false,"title":""}},"cell_type":"markdown","source":"Remember to clean the dataframe with `.reset_index(drop=True)`!"},{"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"d4ac6691-2df0-4de1-b048-9d74fb683bf9","showTitle":false,"title":""},"trusted":false},"cell_type":"code","source":"# W_SCM_001 \n# ERROR - Error in GPT response. No response generated. Retrying in 60 seconds.\n# ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\n# [{'section_header': 'Development Object details>RICEFW Object ID:', 'placeholder_text': '<RICEFW ID>', 'replacement_text': 'W_SCM_001'}, {'section_header': 'Development Object details>RICEFW Object Name:', 'placeholder_text': '<RICEFW Name>', 'replacement_text': 'PR Approval'}, {'section_header': 'Development Object details>Workstream:', 'placeholder_text': '<Choose one of the workstream below:\\n(   ) HxM\\t(   ) FI            (   ) WAM      (   ) IS-U\\n(   ) Tax   \\t(   ) Data\\t(   ) SCM (   ) Tech>', 'replacement_text': '(   ) FI'}, {'section_header': 'Development Object details>Type of development', 'placeholder_text':\n\n# W_FIN_001\n#/json error ran again no prblems\n# F_FIN_002\n#good\n# F_FIN_001\n#good other than *** WARNING: skipped 6263 bytes of output ***\n# E_WAM_PS_017\n#Invalid JSON response, then good\n# E_WAM_PS_016\n#looks good\n# E_FIN_002\n#good\n# E_FIN_001\n#good\n# c-fin001\n# good but *** WARNING: skipped 74481 bytes of output ***\n#E scm 029\n#good but *** WARNING: skipped 24733 bytes of output ***","execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}}]},{"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"27f72a32-d5da-4ed3-8245-940704545f19","showTitle":false,"title":""},"trusted":false},"cell_type":"code","source":"## Filter which requirements to process, e.g. one of each type\n\n# To select specific requirement IDs:\ndf_requirements_sel = df_requirements_clean\\\n  .query('''`RICEFW ID` in [\"E_SCM_029\"]''')\\\n  .reset_index()\\\n  .drop('index', axis=1)\n\n# # To select specific requirement IDs:\n# df_requirements_sel = df_requirements_clean\\\n#   .query('''`RICEFW ID` in [\"I_WAM_T&D_012\"]''')\\\n#   .reset_index()\\\n#   .drop('index', axis=1)\n\n# To do a full run:\n# df_requirements_sel = df_requirements_clean[:1]\n\n# To select n from each category\n# n_per_category = 2\n# counter=1\n# for requirementtype in df_requirements_clean['RICEFW Type'].str.upper().drop_duplicates():\n#   tempdf=df_requirements_clean[df_requirements_clean['RICEFW Type'].str.upper()==requirementtype].head(n_per_category)\n#   if counter==1:\n#     df_requirements_sel=tempdf\n#   else:\n#     df_requirements_sel=pd.concat([df_requirements_sel,tempdf],ignore_index=True)\n#   counter=counter+1\n# df_requirements_sel = df_requirements_sel.reset_index().drop('index', axis=1)\n\n# Get only requirements with detailed descriptions\n# df_requirements_sel = df_requirements_clean[df_requirements_clean['Detailed Description'].str.strip()!=''].reset_index(drop=True)","execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}}]},{"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"1b66b3d6-574a-432b-9054-67d323598bcf","showTitle":false,"title":""},"trusted":false},"cell_type":"code","source":"# df_results","execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}}]},{"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"81425f47-d08a-454b-98ac-60152aaf42be","showTitle":false,"title":""},"trusted":false},"cell_type":"code","source":"df_control = get_df_control(df_requirements_sel)\ndf_results = get_df_results(df_requirements_sel)\ndf_validation = get_df_validation()\ndf_errors = get_df_errors()","execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}}]},{"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"d274ada0-ebc0-47f9-8204-7c847aa51281","showTitle":false,"title":""}},"cell_type":"markdown","source":"## 4. Iterate through selected requirements and populate the templates for each one"},{"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"9beabb88-017a-4479-979e-1e0b82f5a080","showTitle":false,"title":""}},"cell_type":"markdown","source":"### 4a. Main execution - Check here for runtime details & audit logs"},{"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"7cea1f5c-d4e4-4630-a880-be5a9497937d","showTitle":false,"title":""},"trusted":false},"cell_type":"code","source":"# process_chunk(\"paragraph\",\n#                   index_chunk,\n#                   chunk,\n#                   output_dict,\n#                   index_req,\n#                   #row,\n#                   prompt,\n#                   systemprompt,\n#                   citation_prompt,\n#                   templatename,\n#                   df_control,\n#                   df_results,\n#                   df_errors,\n#                   df_validation,\n#                   fsd_lookup,\n#                   bpd_lookup,\n#                   transcripts_lookup,\n#                   images_lookup,\n#                   knowledge_base_docs,\n#                   temperature,\n#                   verbose,\n#                   validation,\n#                   backup_strict,\n#                   log_id_doc)\n  \n#   print(content_type)\n#   print()\n#   print(index_chunk)\n#   print()\n#   print(chunk)\n#   print()\n#   print(output_dict)\n#   print()\n#   print(index_req)\n#   print()\n#   print(prompt)\n#   print()\n#   print(systemprompt)\n#   print()\n#   print(citation_prompt)\n#   print()\n#   print(templatename)\n#   print()\n#   print(df_control)\n#   print()\n#   print(df_results)\n#   print()\n#   print(df_errors)\n#   print()\n#   print(df_validation)\n#   print()\n#   print(fsd_lookup)\n#   print()\n#   print(bpd_lookup)\n#   print()\n#   print(transcripts_lookup)\n#   print()\n#   print(images_lookup)\n#   print()\n#   print(knowledge_base_docs)\n#   print()\n#   print(temperature)\n#   print()\n#   print(verbose)\n#   print()\n#   print(validation)\n#   print()\n#   print(backup_strict)\n#   print()\n#   print(log_id_doc)\n#   # raise Exception(\"skipped chunk processing in debug mode. Edit cmd 6 in SAP_FDD_CORE to turn off debug mode.\") # DEBUG\n\n#   # restartability idea - check if replacement texts for chunk already populated, if so, skip to next chunk\n#   # this way, if the run gets interrupted, it can just be restarted\n#   if content_type == \"paragraphs\":\n#     if df_control.loc[index_req, \"LastChunk_contenttype\"] == \"tables\":\n#       # if the paragraphs are done already (pointer is at tables), skip all paragraphs\n#       log(f\"[{log_id_doc}] {content_type} chunk {index_chunk+1}/{len(output_dict[content_type]['chunks'])} already populated. skipping to next chunk.\")\n#       return\n#     elif df_control.loc[index_req, \"LastChunk_contenttype\"] == \"paragraphs\":\n#       # if the paragraphs are started, but not done (pointer is at paragraphs)\n#       if df_control.loc[index_req, \"LastChunk_index\"] >= index_chunk:\n#         #  if the last written chunk number is higher than the current, skip current\n#         log(f\"[{log_id_doc}] {content_type} chunk {index_chunk+1}/{len(output_dict[content_type]['chunks'])} already populated. skipping to next chunk.\")\n#         return\n#       # else: #  if the last written chunk number is lower than the current, go on and populate for current\n#   elif content_type == \"tables\":\n#     if df_control.loc[index_req, \"LastChunk_contenttype\"] == \"tables\":\n#       # if the tables are started, but not done (pointer is at tables)\n#       if df_control.loc[index_req, \"LastChunk_index\"] >= index_chunk:\n#         #  if the last written chunk number is higher than the current, skip current\n#         log(f\"[{log_id_doc}] {content_type} chunk {index_chunk+1}/{len(output_dict[content_type]['chunks'])} already populated. skipping to next chunk.\")\n#         return\n#       # else: #  if the last written chunk number is lower than the current, go on and populate for current\n#     # else: if the pointer is still at paragraphs, go on and populate (happens only for first table after paragraphs are done)\n#   # else: nothing populated yet (pointer is blank), go on and populate first paragraph & chunk\n\n#   if df_control.loc[index_req, \"LastChunk_contenttype\"] == content_type and df_control.loc[index_req, \"LastChunk_index\"] >= index_chunk:\n#     log(f\"[{log_id_doc}] {content_type} chunk {index_chunk+1}/{len(output_dict[content_type]['chunks'])} already populated. skipping to next chunk.\")\n#     return  \n  \n#   log(f\"[{log_id_doc}] Processing {content_type} chunk {index_chunk+1}/{len(output_dict[content_type]['chunks'])} ... \")\n#   curr_prompt = prompt\\\n#     .replace(\"{requirement}\", df_control.loc[index_req, \"Requirement Cleansed\"])\\\n#     .replace(\"{jsontemplate}\", json.dumps(chunk))\\\n#     .replace(\"{RICEFWType}\", df_control.loc[index_req, \"RICEFW Type\"])\\\n#     .replace(\"{RICEFWID}\", df_control.loc[index_req, \"RICEFW ID\"])\\\n#     .replace(\"{RICEFWName}\", df_control.loc[index_req, \"RICEFW Name\"])\\\n#     .replace(\"{requirement_detailed_description}\",df_control.loc[index_req, \"Detailed Description\"])\\\n#     .replace(\"{citation_prompt}\",citation_prompt)\n\n#   if transcripts_lookup != None:\n#     curr_prompt = curr_prompt.replace(\"{transcripts_lookup}\", f\"\"\"\\n\\nInfo on requirement from workshop transcripts: \\n```\\n{transcripts_lookup}\\n```\\n\"\"\")\n#   else: curr_prompt = curr_prompt.replace(\"{transcripts_lookup}\", \"\")\n\n#   if fsd_lookup != None:\n#     curr_prompt = curr_prompt.replace(\"{fsd_lookup}\", f\"\"\"\\n\\nInfo on requirement from FSDs for other projects (Use for reference only and do not copy as is, don't refer to specific people, entity or asset names): \\n```\\n{fsd_lookup}\\n```\\n\"\"\")\n#   else: curr_prompt = curr_prompt.replace(\"{fsd_lookup}\", \"\")\n\n#   if bpd_lookup != None:\n#     curr_prompt = curr_prompt.replace(\"{bpd_lookup}\", f\"\"\"\\n\\nInfo on requirement from business process docs (Use for reference only and do not copy as is, don't refer to specific people, entity or asset names): \\n```\\n{bpd_lookup}\\n```\\n\"\"\")\n#   else: curr_prompt = curr_prompt.replace(\"{bpd_lookup}\", \"\")\n\n#   if knowledge_base_docs != None:\n#     kb_docs_lookup = knowledge_base_docs[templatename][\"placeholders\"][content_type][\"chunks\"][index_chunk]\n#     curr_prompt = curr_prompt.replace(\"{knowledge_base_docs}\", f\"\"\"\\n\\nExamples of 'what good looks like' from FSDs for other projects, not directly related to this requirement (Use for reference only and do not copy as is, don't refer to specific people, entity or asset names): \\n```\\n{kb_docs_lookup}\\n```\\n\"\"\")\n#   else: curr_prompt = curr_prompt.replace(\"{knowledge_base_docs}\", \"\")\n\n#   if verbose: print(curr_prompt)\n\n    \n\n#   response = gpt4(prompt=curr_prompt, context=systemprompt, temperature=temperature, max_tokens=6000, large=True, tries=3).replace('\\\\\\\\','/').replace('}],','},')\n#   #response = gpt35(prompt=curr_prompt, context=systemprompt, temperature=temperature, max_tokens=10000, tries=3)\n  \n#   if validation: \n#     # print(\"writing prompt to validation df\") # DEBUG\n#     val_row = {'RICEFW ID': df_control.loc[index_req, \"RICEFW ID\"],\n#               'RICEFW Name': df_control.loc[index_req, \"RICEFW Name\"],\n#               'Chunk Numb': index_chunk + 1,\n#               'Prompt': curr_prompt,\n#               'Response': response}\n#     df_validation.loc[len(df_validation.index)] = val_row\n\n#   fix_json_system_prompt='You are an expert at fixing JSONs'\n#   fix_json_user_prompt='''Fix the following JSON so that it can be successfully loaded by json.loads, response should be only the fixed JSON:\n#   {error_json}'''\n\n#   try:\n#     response_json = json.loads(response, strict=False)\n#   except:\n#     print(\"ERROR - Error in populating requirement. GPT response could not be parsed as JSON. Asking GPT to correct response...\")\n#     response=gpt4(prompt=fix_json_user_prompt.replace('{error_json}',response), context=fix_json_system_prompt, temperature=0, max_tokens=15000, large=True, tries=3)\n#     try:\n#       response_json = json.loads(response, strict=False)\n#     except Exception as err:\n#       # GPT returned ill-formatted JSON in its response -> Skip to next requirement\n#       log(f\"[{log_id_doc}] ERROR - Error in populating requirement. GPT response could not be parsed as JSON. This event has been noted in the error table.\", color=\"red\")\n#       print(\"Traceback:\")\n#       print(err)\n#       if verbose:\n#         print(\"Full GPT Prompt response:\")\n#         print(response)\n#       # Append incomplete response to error capturing dataframe\n#       err_row = {'RICEFW ID': df_control.loc[index_req, \"RICEFW ID\"],\n#                   'RICEFW Name': df_control.loc[index_req, \"RICEFW Name\"],\n#                   'LastChunk_contenttype': content_type,\n#                   'LastChunk_index': index_chunk,\n#                   'response': response}\n#       df_errors.loc[len(df_errors.index)] = err_row\n#       raise Exception(\"Invalid JSON response\") # will jump into upper-level try-block, thus skipping to next requirement\n\n#   # check if all elements contain all required JSON attributes ('section_header', placeholder_text', 'replacement_text')\n#   # this is basically a big try - except\n#   for elem in response_json:\n#     elem_keys = list(elem.keys())\n#     # print(elem_keys) # DEBUG\n#     if not (\"section_header\" in elem_keys and \"placeholder_text\" in elem_keys and \"replacement_text\" in elem_keys):\n#       # GPT returned ill-formatted JSON in its response -> Skip to next requirement\n#       log(f\"[{log_id_doc}] ERROR - Error in populating requirement. GPT response is valid JSON, but does not contain all required fields. This event has been noted in the error table.\", color=\"red\")\n#       if verbose:\n#         print(\"Full GPT Prompt response:\")\n#         print(response)\n#       # Append incomplete response to error capturing dataframe\n#       err_row = {'RICEFW ID': df_control.loc[index_req, \"RICEFW ID\"],\n#                   'RICEFW Name': df_control.loc[index_req, \"RICEFW Name\"],\n#                   'LastChunk_contenttype': content_type,\n#                   'LastChunk_index': index_chunk,\n#                   'response': response}\n#       df_errors.loc[len(df_errors.index)] = err_row\n#       raise Exception(\"Valid, but incomplete JSON response\") # will jump into upper-level try-block, thus skipping to next requirement   \n  \n#   # if no exceptions above (i.e. the response is valid and complete) - write response to result\n#   output_dict[content_type][\"chunks\"][index_chunk] = response_json\n  \n#   # write back to control table\n#   df_results.loc[index_req, \"JSON\"] = json.dumps(output_dict)\n#   df_control.loc[index_req, \"LastChunk_contenttype\"] = content_type\n#   df_control.loc[index_req, \"LastChunk_index\"] = index_chunk\n#   if backup_strict: backup(df_control)\n\n#   log(f\"[{log_id_doc}] Processing {content_type} chunk {index_chunk+1}/{len(output_dict[content_type]['chunks'])} ... done.\")","execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}}]},{"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"dbca3ecc-96e2-4772-ac9b-3b02dbfedc9d","showTitle":false,"title":""},"trusted":false},"cell_type":"code","source":"generate_output_batch(df_control,\n                      df_results,\n                      df_mapping,\n                      df_errors,\n                      df_validation,\n                      folder_input,\n                      index_fsd=index_fsd, #optional\n                      index_bpd=index_bpd, #optional\n                      index_transcripts=index_transcripts, #optional\n                      verbose=False, # True will output all prompts as well as all placeholder replacements in the doc\n                      validation = True, # true will store chunks prompt and response in df_validation \n                      citation=False, # True will cite instances where information is referenced\n                      template_max_tokens_per_chunk=400,\n                      individual_sections=False,\n                      halt_on_errors = False\n                      )","execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-bold\">[2023-10-19 23:20:46] [Main] WARNING - Knowledge Base for Input FSDs is not set. Pass it to the main function with the &#39;knowledge_base_docs&#39; argument.</span>\n[2023-10-19 23:20:46] [Main] Parsing templates\n\nParsing &#39;OGE_Functional Specification_Document_CNV_Template__Approved.docx&#39;\nWarning: Token count for paragraphs is 3777 and thus higher than the specified max (400). Splitting paragraphs into 10 chunks, retrieve them by using placeholders[&#39;paragraphs&#39;][&#39;chunks&#39;][n] or increase the max_tokens_per_chunk parameter.\n\nParsing &#39;OGE_Functional Specification Document_FRM Template__Approved.docx&#39;\nWarning: Token count for tables is 1596 and thus higher than the specified max (400). Splitting tables into 4 chunks, retrieve them by using placeholders[&#39;tables&#39;][&#39;chunks&#39;][n] or increase the max_tokens_per_chunk parameter.\n\nParsing &#39;OGE_Functional Specification_Document_INT_Template__Approved.docx&#39;\nWarning: Token count for tables is 3091 and thus higher than the specified max (400). Splitting tables into 8 chunks, retrieve them by using placeholders[&#39;tables&#39;][&#39;chunks&#39;][n] or increase the max_tokens_per_chunk parameter.\n\nParsing &#39;OGE_Functional Specification Document_RPT Template__Approved.docx&#39;\nWarning: Token count for tables is 4039 and thus higher than the specified max (400). Splitting tables into 11 chunks, retrieve them by using placeholders[&#39;tables&#39;][&#39;chunks&#39;][n] or increase the max_tokens_per_chunk parameter.\n\nParsing &#39;OGE_Functional Specification Document_WKF Template__Approved.docx&#39;\nWarning: Token count for tables is 1547 and thus higher than the specified max (400). Splitting tables into 4 chunks, retrieve them by using placeholders[&#39;tables&#39;][&#39;chunks&#39;][n] or increase the max_tokens_per_chunk parameter.\n\nParsing &#39;OGE_Functional Specification Document_ENH Template__Approved.docx&#39;\nWarning: Token count for tables is 1755 and thus higher than the specified max (400). Splitting tables into 5 chunks, retrieve them by using placeholders[&#39;tables&#39;][&#39;chunks&#39;][n] or increase the max_tokens_per_chunk parameter.\n[2023-10-19 23:20:51] [Document 1/2] Processing Requirement : E_SCM_029 (Ability to automatically calculate system suggested supplier lead time)\n[2023-10-19 23:20:51]  checkpoint 1 \n[2023-10-19 23:20:51] [Document 1/2] Looking up requirement in the transcripts index via the ACS approach ... \n{&#39;error&#39;: {&#39;message&#39;: &#34;This model&#39;s maximum context length is 8192 tokens. However, you requested 11259 tokens (7259 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.&#34;, &#39;type&#39;: &#39;invalid_request_error&#39;, &#39;param&#39;: &#39;messages&#39;, &#39;code&#39;: &#39;context_length_exceeded&#39;}}\nERROR - Error in GPT response. Full response:\n{\n  &#34;error&#34;: {\n    &#34;message&#34;: &#34;This model&#39;s maximum context length is 8192 tokens. However, you requested 11259 tokens (7259 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.&#34;,\n    &#34;type&#34;: &#34;invalid_request_error&#34;,\n    &#34;param&#34;: &#34;messages&#34;,\n    &#34;code&#34;: &#34;context_length_exceeded&#34;\n  }\n}\n\nTrying again in 15 seconds.\n{&#39;error&#39;: {&#39;message&#39;: &#34;This model&#39;s maximum context length is 8192 tokens. However, you requested 11259 tokens (7259 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.&#34;, &#39;type&#39;: &#39;invalid_request_error&#39;, &#39;param&#39;: &#39;messages&#39;, &#39;code&#39;: &#39;context_length_exceeded&#39;}}\nERROR - Error in GPT response. Full response:\n{\n  &#34;error&#34;: {\n    &#34;message&#34;: &#34;This model&#39;s maximum context length is 8192 tokens. However, you requested 11259 tokens (7259 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.&#34;,\n    &#34;type&#34;: &#34;invalid_request_error&#34;,\n    &#34;param&#34;: &#34;messages&#34;,\n    &#34;code&#34;: &#34;context_length_exceeded&#34;\n  }\n}\n\nTrying again in 15 seconds.\n{&#39;error&#39;: {&#39;message&#39;: &#34;This model&#39;s maximum context length is 8192 tokens. However, you requested 11259 tokens (7259 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.&#34;, &#39;type&#39;: &#39;invalid_request_error&#39;, &#39;param&#39;: &#39;messages&#39;, &#39;code&#39;: &#39;context_length_exceeded&#39;}}\nERROR - Error in GPT response. Full response:\n{\n  &#34;error&#34;: {\n    &#34;message&#34;: &#34;This model&#39;s maximum context length is 8192 tokens. However, you requested 11259 tokens (7259 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.&#34;,\n    &#34;type&#34;: &#34;invalid_request_error&#34;,\n    &#34;param&#34;: &#34;messages&#34;,\n    &#34;code&#34;: &#34;context_length_exceeded&#34;\n  }\n}\n\n[2023-10-19 23:21:24] [Document 1/2] Looking up requirement in the transcripts index via the ACS approach ... done\n[2023-10-19 23:21:24] [Document 1/2] Looking up requirement in the FSDs index via the ACS approach ... \n{&#39;error&#39;: {&#39;message&#39;: &#34;This model&#39;s maximum context length is 8192 tokens. However, you requested 11851 tokens (7851 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.&#34;, &#39;type&#39;: &#39;invalid_request_error&#39;, &#39;param&#39;: &#39;messages&#39;, &#39;code&#39;: &#39;context_length_exceeded&#39;}}\nERROR - Error in GPT response. Full response:\n{\n  &#34;error&#34;: {\n    &#34;message&#34;: &#34;This model&#39;s maximum context length is 8192 tokens. However, you requested 11851 tokens (7851 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.&#34;,\n    &#34;type&#34;: &#34;invalid_request_error&#34;,\n    &#34;param&#34;: &#34;messages&#34;,\n    &#34;code&#34;: &#34;context_length_exceeded&#34;\n  }\n}\n\nTrying again in 15 seconds.\n{&#39;error&#39;: {&#39;message&#39;: &#34;This model&#39;s maximum context length is 8192 tokens. However, you requested 11851 tokens (7851 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.&#34;, &#39;type&#39;: &#39;invalid_request_error&#39;, &#39;param&#39;: &#39;messages&#39;, &#39;code&#39;: &#39;context_length_exceeded&#39;}}\nERROR - Error in GPT response. Full response:\n{\n  &#34;error&#34;: {\n    &#34;message&#34;: &#34;This model&#39;s maximum context length is 8192 tokens. However, you requested 11851 tokens (7851 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.&#34;,\n    &#34;type&#34;: &#34;invalid_request_error&#34;,\n    &#34;param&#34;: &#34;messages&#34;,\n    &#34;code&#34;: &#34;context_length_exceeded&#34;\n  }\n}\n\nTrying again in 15 seconds.\n{&#39;error&#39;: {&#39;message&#39;: &#34;This model&#39;s maximum context length is 8192 tokens. However, you requested 11851 tokens (7851 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.&#34;, &#39;type&#39;: &#39;invalid_request_error&#39;, &#39;param&#39;: &#39;messages&#39;, &#39;code&#39;: &#39;context_length_exceeded&#39;}}\nERROR - Error in GPT response. Full response:\n{\n  &#34;error&#34;: {\n    &#34;message&#34;: &#34;This model&#39;s maximum context length is 8192 tokens. However, you requested 11851 tokens (7851 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.&#34;,\n    &#34;type&#34;: &#34;invalid_request_error&#34;,\n    &#34;param&#34;: &#34;messages&#34;,\n    &#34;code&#34;: &#34;context_length_exceeded&#34;\n  }\n}\n\n[2023-10-19 23:21:57] [Document 1/2] Looking up requirement in the FSDs index via the ACS approach ... done\n[2023-10-19 23:21:57] [Document 1/2] Looking up requirement in the BPDs index via the ACS approach ... \n{&#39;error&#39;: {&#39;message&#39;: &#34;This model&#39;s maximum context length is 8192 tokens. However, your messages resulted in 8509 tokens. Please reduce the length of the messages.&#34;, &#39;type&#39;: &#39;invalid_request_error&#39;, &#39;param&#39;: &#39;messages&#39;, &#39;code&#39;: &#39;context_length_exceeded&#39;}}\nERROR - Error in GPT response. Full response:\n{\n  &#34;error&#34;: {\n    &#34;message&#34;: &#34;This model&#39;s maximum context length is 8192 tokens. However, your messages resulted in 8509 tokens. Please reduce the length of the messages.&#34;,\n    &#34;type&#34;: &#34;invalid_request_error&#34;,\n    &#34;param&#34;: &#34;messages&#34;,\n    &#34;code&#34;: &#34;context_length_exceeded&#34;\n  }\n}\n\nTrying again in 15 seconds.\n{&#39;error&#39;: {&#39;message&#39;: &#34;This model&#39;s maximum context length is 8192 tokens. However, your messages resulted in 8509 tokens. Please reduce the length of the messages.&#34;, &#39;type&#39;: &#39;invalid_request_error&#39;, &#39;param&#39;: &#39;messages&#39;, &#39;code&#39;: &#39;context_length_exceeded&#39;}}\nERROR - Error in GPT response. Full response:\n{\n  &#34;error&#34;: {\n    &#34;message&#34;: &#34;This model&#39;s maximum context length is 8192 tokens. However, your messages resulted in 8509 tokens. Please reduce the length of the messages.&#34;,\n    &#34;type&#34;: &#34;invalid_request_error&#34;,\n    &#34;param&#34;: &#34;messages&#34;,\n    &#34;code&#34;: &#34;context_length_exceeded&#34;\n  }\n}\n\nTrying again in 15 seconds.\n{&#39;error&#39;: {&#39;message&#39;: &#34;This model&#39;s maximum context length is 8192 tokens. However, your messages resulted in 8509 tokens. Please reduce the length of the messages.&#34;, &#39;type&#39;: &#39;invalid_request_error&#39;, &#39;param&#39;: &#39;messages&#39;, &#39;code&#39;: &#39;context_length_exceeded&#39;}}\nERROR - Error in GPT response. Full response:\n{\n  &#34;error&#34;: {\n    &#34;message&#34;: &#34;This model&#39;s maximum context length is 8192 tokens. However, your messages resulted in 8509 tokens. Please reduce the length of the messages.&#34;,\n    &#34;type&#34;: &#34;invalid_request_error&#34;,\n    &#34;param&#34;: &#34;messages&#34;,\n    &#34;code&#34;: &#34;context_length_exceeded&#34;\n  }\n}\n\n[2023-10-19 23:22:29] [Document 1/2] Looking up requirement in the BPDs index via the ACS approach ... done\n[2023-10-19 23:22:29] [Document 1/2] Processing paragraphs chunk 1/1 ... \n********************Sending 3.5 turbo request\nToken count:\nWarning: gpt-4 may update over time. Returning num tokens assuming gpt-4-0613.\nWarning: gpt-4 may update over time. Returning num tokens assuming gpt-4-0613.\n435\n{&#39;error&#39;: {&#39;message&#39;: &#34;This model&#39;s maximum context length is 8192 tokens. However, you requested 10442 tokens (442 in the messages, 10000 in the completion). Please reduce the length of the messages or completion.&#34;, &#39;type&#39;: &#39;invalid_request_error&#39;, &#39;param&#39;: &#39;messages&#39;, &#39;code&#39;: &#39;context_length_exceeded&#39;}}\nERROR - Error in GPT response. Full response:\n{\n  &#34;error&#34;: {\n    &#34;message&#34;: &#34;This model&#39;s maximum context length is 8192 tokens. However, you requested 10442 tokens (442 in the messages, 10000 in the completion). Please reduce the length of the messages or completion.&#34;,\n    &#34;type&#34;: &#34;invalid_request_error&#34;,\n    &#34;param&#34;: &#34;messages&#34;,\n    &#34;code&#34;: &#34;context_length_exceeded&#34;\n  }\n}\n\nTrying again in 15 seconds.\n{&#39;error&#39;: {&#39;message&#39;: &#34;This model&#39;s maximum context length is 8192 tokens. However, you requested 10442 tokens (442 in the messages, 10000 in the completion). Please reduce the length of the messages or completion.&#34;, &#39;type&#39;: &#39;invalid_request_error&#39;, &#39;param&#39;: &#39;messages&#39;, &#39;code&#39;: &#39;context_length_exceeded&#39;}}\nERROR - Error in GPT response. Full response:\n{\n  &#34;error&#34;: {\n    &#34;message&#34;: &#34;This model&#39;s maximum context length is 8192 tokens. However, you requested 10442 tokens (442 in the messages, 10000 in the completion). Please reduce the length of the messages or completion.&#34;,\n    &#34;type&#34;: &#34;invalid_request_error&#34;,\n    &#34;param&#34;: &#34;messages&#34;,\n    &#34;code&#34;: &#34;context_length_exceeded&#34;\n  }\n}\n\nTrying again in 15 seconds.\n{&#39;error&#39;: {&#39;message&#39;: &#34;This model&#39;s maximum context length is 8192 tokens. However, you requested 10442 tokens (442 in the messages, 10000 in the completion). Please reduce the length of the messages or completion.&#34;, &#39;type&#39;: &#39;invalid_request_error&#39;, &#39;param&#39;: &#39;messages&#39;, &#39;code&#39;: &#39;context_length_exceeded&#39;}}\nERROR - Error in GPT response. Full response:\n{\n  &#34;error&#34;: {\n    &#34;message&#34;: &#34;This model&#39;s maximum context length is 8192 tokens. However, you requested 10442 tokens (442 in the messages, 10000 in the completion). Please reduce the length of the messages or completion.&#34;,\n    &#34;type&#34;: &#34;invalid_request_error&#34;,\n    &#34;param&#34;: &#34;messages&#34;,\n    &#34;code&#34;: &#34;context_length_exceeded&#34;\n  }\n}\n\nERROR - Error in populating requirement. GPT response could not be parsed as JSON. Asking GPT to correct response...\n</div>"},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"><span class=\"ansi-bold\">[2023-10-19 23:20:46] [Main] WARNING - Knowledge Base for Input FSDs is not set. Pass it to the main function with the &#39;knowledge_base_docs&#39; argument.</span>\n[2023-10-19 23:20:46] [Main] Parsing templates\n\nParsing &#39;OGE_Functional Specification_Document_CNV_Template__Approved.docx&#39;\nWarning: Token count for paragraphs is 3777 and thus higher than the specified max (400). Splitting paragraphs into 10 chunks, retrieve them by using placeholders[&#39;paragraphs&#39;][&#39;chunks&#39;][n] or increase the max_tokens_per_chunk parameter.\n\nParsing &#39;OGE_Functional Specification Document_FRM Template__Approved.docx&#39;\nWarning: Token count for tables is 1596 and thus higher than the specified max (400). Splitting tables into 4 chunks, retrieve them by using placeholders[&#39;tables&#39;][&#39;chunks&#39;][n] or increase the max_tokens_per_chunk parameter.\n\nParsing &#39;OGE_Functional Specification_Document_INT_Template__Approved.docx&#39;\nWarning: Token count for tables is 3091 and thus higher than the specified max (400). Splitting tables into 8 chunks, retrieve them by using placeholders[&#39;tables&#39;][&#39;chunks&#39;][n] or increase the max_tokens_per_chunk parameter.\n\nParsing &#39;OGE_Functional Specification Document_RPT Template__Approved.docx&#39;\nWarning: Token count for tables is 4039 and thus higher than the specified max (400). Splitting tables into 11 chunks, retrieve them by using placeholders[&#39;tables&#39;][&#39;chunks&#39;][n] or increase the max_tokens_per_chunk parameter.\n\nParsing &#39;OGE_Functional Specification Document_WKF Template__Approved.docx&#39;\nWarning: Token count for tables is 1547 and thus higher than the specified max (400). Splitting tables into 4 chunks, retrieve them by using placeholders[&#39;tables&#39;][&#39;chunks&#39;][n] or increase the max_tokens_per_chunk parameter.\n\nParsing &#39;OGE_Functional Specification Document_ENH Template__Approved.docx&#39;\nWarning: Token count for tables is 1755 and thus higher than the specified max (400). Splitting tables into 5 chunks, retrieve them by using placeholders[&#39;tables&#39;][&#39;chunks&#39;][n] or increase the max_tokens_per_chunk parameter.\n[2023-10-19 23:20:51] [Document 1/2] Processing Requirement : E_SCM_029 (Ability to automatically calculate system suggested supplier lead time)\n[2023-10-19 23:20:51]  checkpoint 1 \n[2023-10-19 23:20:51] [Document 1/2] Looking up requirement in the transcripts index via the ACS approach ... \n{&#39;error&#39;: {&#39;message&#39;: &#34;This model&#39;s maximum context length is 8192 tokens. However, you requested 11259 tokens (7259 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.&#34;, &#39;type&#39;: &#39;invalid_request_error&#39;, &#39;param&#39;: &#39;messages&#39;, &#39;code&#39;: &#39;context_length_exceeded&#39;}}\nERROR - Error in GPT response. Full response:\n{\n  &#34;error&#34;: {\n    &#34;message&#34;: &#34;This model&#39;s maximum context length is 8192 tokens. However, you requested 11259 tokens (7259 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.&#34;,\n    &#34;type&#34;: &#34;invalid_request_error&#34;,\n    &#34;param&#34;: &#34;messages&#34;,\n    &#34;code&#34;: &#34;context_length_exceeded&#34;\n  }\n}\n\nTrying again in 15 seconds.\n{&#39;error&#39;: {&#39;message&#39;: &#34;This model&#39;s maximum context length is 8192 tokens. However, you requested 11259 tokens (7259 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.&#34;, &#39;type&#39;: &#39;invalid_request_error&#39;, &#39;param&#39;: &#39;messages&#39;, &#39;code&#39;: &#39;context_length_exceeded&#39;}}\nERROR - Error in GPT response. Full response:\n{\n  &#34;error&#34;: {\n    &#34;message&#34;: &#34;This model&#39;s maximum context length is 8192 tokens. However, you requested 11259 tokens (7259 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.&#34;,\n    &#34;type&#34;: &#34;invalid_request_error&#34;,\n    &#34;param&#34;: &#34;messages&#34;,\n    &#34;code&#34;: &#34;context_length_exceeded&#34;\n  }\n}\n\nTrying again in 15 seconds.\n{&#39;error&#39;: {&#39;message&#39;: &#34;This model&#39;s maximum context length is 8192 tokens. However, you requested 11259 tokens (7259 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.&#34;, &#39;type&#39;: &#39;invalid_request_error&#39;, &#39;param&#39;: &#39;messages&#39;, &#39;code&#39;: &#39;context_length_exceeded&#39;}}\nERROR - Error in GPT response. Full response:\n{\n  &#34;error&#34;: {\n    &#34;message&#34;: &#34;This model&#39;s maximum context length is 8192 tokens. However, you requested 11259 tokens (7259 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.&#34;,\n    &#34;type&#34;: &#34;invalid_request_error&#34;,\n    &#34;param&#34;: &#34;messages&#34;,\n    &#34;code&#34;: &#34;context_length_exceeded&#34;\n  }\n}\n\n[2023-10-19 23:21:24] [Document 1/2] Looking up requirement in the transcripts index via the ACS approach ... done\n[2023-10-19 23:21:24] [Document 1/2] Looking up requirement in the FSDs index via the ACS approach ... \n{&#39;error&#39;: {&#39;message&#39;: &#34;This model&#39;s maximum context length is 8192 tokens. However, you requested 11851 tokens (7851 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.&#34;, &#39;type&#39;: &#39;invalid_request_error&#39;, &#39;param&#39;: &#39;messages&#39;, &#39;code&#39;: &#39;context_length_exceeded&#39;}}\nERROR - Error in GPT response. Full response:\n{\n  &#34;error&#34;: {\n    &#34;message&#34;: &#34;This model&#39;s maximum context length is 8192 tokens. However, you requested 11851 tokens (7851 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.&#34;,\n    &#34;type&#34;: &#34;invalid_request_error&#34;,\n    &#34;param&#34;: &#34;messages&#34;,\n    &#34;code&#34;: &#34;context_length_exceeded&#34;\n  }\n}\n\nTrying again in 15 seconds.\n{&#39;error&#39;: {&#39;message&#39;: &#34;This model&#39;s maximum context length is 8192 tokens. However, you requested 11851 tokens (7851 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.&#34;, &#39;type&#39;: &#39;invalid_request_error&#39;, &#39;param&#39;: &#39;messages&#39;, &#39;code&#39;: &#39;context_length_exceeded&#39;}}\nERROR - Error in GPT response. Full response:\n{\n  &#34;error&#34;: {\n    &#34;message&#34;: &#34;This model&#39;s maximum context length is 8192 tokens. However, you requested 11851 tokens (7851 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.&#34;,\n    &#34;type&#34;: &#34;invalid_request_error&#34;,\n    &#34;param&#34;: &#34;messages&#34;,\n    &#34;code&#34;: &#34;context_length_exceeded&#34;\n  }\n}\n\nTrying again in 15 seconds.\n{&#39;error&#39;: {&#39;message&#39;: &#34;This model&#39;s maximum context length is 8192 tokens. However, you requested 11851 tokens (7851 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.&#34;, &#39;type&#39;: &#39;invalid_request_error&#39;, &#39;param&#39;: &#39;messages&#39;, &#39;code&#39;: &#39;context_length_exceeded&#39;}}\nERROR - Error in GPT response. Full response:\n{\n  &#34;error&#34;: {\n    &#34;message&#34;: &#34;This model&#39;s maximum context length is 8192 tokens. However, you requested 11851 tokens (7851 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.&#34;,\n    &#34;type&#34;: &#34;invalid_request_error&#34;,\n    &#34;param&#34;: &#34;messages&#34;,\n    &#34;code&#34;: &#34;context_length_exceeded&#34;\n  }\n}\n\n[2023-10-19 23:21:57] [Document 1/2] Looking up requirement in the FSDs index via the ACS approach ... done\n[2023-10-19 23:21:57] [Document 1/2] Looking up requirement in the BPDs index via the ACS approach ... \n{&#39;error&#39;: {&#39;message&#39;: &#34;This model&#39;s maximum context length is 8192 tokens. However, your messages resulted in 8509 tokens. Please reduce the length of the messages.&#34;, &#39;type&#39;: &#39;invalid_request_error&#39;, &#39;param&#39;: &#39;messages&#39;, &#39;code&#39;: &#39;context_length_exceeded&#39;}}\nERROR - Error in GPT response. Full response:\n{\n  &#34;error&#34;: {\n    &#34;message&#34;: &#34;This model&#39;s maximum context length is 8192 tokens. However, your messages resulted in 8509 tokens. Please reduce the length of the messages.&#34;,\n    &#34;type&#34;: &#34;invalid_request_error&#34;,\n    &#34;param&#34;: &#34;messages&#34;,\n    &#34;code&#34;: &#34;context_length_exceeded&#34;\n  }\n}\n\nTrying again in 15 seconds.\n{&#39;error&#39;: {&#39;message&#39;: &#34;This model&#39;s maximum context length is 8192 tokens. However, your messages resulted in 8509 tokens. Please reduce the length of the messages.&#34;, &#39;type&#39;: &#39;invalid_request_error&#39;, &#39;param&#39;: &#39;messages&#39;, &#39;code&#39;: &#39;context_length_exceeded&#39;}}\nERROR - Error in GPT response. Full response:\n{\n  &#34;error&#34;: {\n    &#34;message&#34;: &#34;This model&#39;s maximum context length is 8192 tokens. However, your messages resulted in 8509 tokens. Please reduce the length of the messages.&#34;,\n    &#34;type&#34;: &#34;invalid_request_error&#34;,\n    &#34;param&#34;: &#34;messages&#34;,\n    &#34;code&#34;: &#34;context_length_exceeded&#34;\n  }\n}\n\nTrying again in 15 seconds.\n{&#39;error&#39;: {&#39;message&#39;: &#34;This model&#39;s maximum context length is 8192 tokens. However, your messages resulted in 8509 tokens. Please reduce the length of the messages.&#34;, &#39;type&#39;: &#39;invalid_request_error&#39;, &#39;param&#39;: &#39;messages&#39;, &#39;code&#39;: &#39;context_length_exceeded&#39;}}\nERROR - Error in GPT response. Full response:\n{\n  &#34;error&#34;: {\n    &#34;message&#34;: &#34;This model&#39;s maximum context length is 8192 tokens. However, your messages resulted in 8509 tokens. Please reduce the length of the messages.&#34;,\n    &#34;type&#34;: &#34;invalid_request_error&#34;,\n    &#34;param&#34;: &#34;messages&#34;,\n    &#34;code&#34;: &#34;context_length_exceeded&#34;\n  }\n}\n\n[2023-10-19 23:22:29] [Document 1/2] Looking up requirement in the BPDs index via the ACS approach ... done\n[2023-10-19 23:22:29] [Document 1/2] Processing paragraphs chunk 1/1 ... \n********************Sending 3.5 turbo request\nToken count:\nWarning: gpt-4 may update over time. Returning num tokens assuming gpt-4-0613.\nWarning: gpt-4 may update over time. Returning num tokens assuming gpt-4-0613.\n435\n{&#39;error&#39;: {&#39;message&#39;: &#34;This model&#39;s maximum context length is 8192 tokens. However, you requested 10442 tokens (442 in the messages, 10000 in the completion). Please reduce the length of the messages or completion.&#34;, &#39;type&#39;: &#39;invalid_request_error&#39;, &#39;param&#39;: &#39;messages&#39;, &#39;code&#39;: &#39;context_length_exceeded&#39;}}\nERROR - Error in GPT response. Full response:\n{\n  &#34;error&#34;: {\n    &#34;message&#34;: &#34;This model&#39;s maximum context length is 8192 tokens. However, you requested 10442 tokens (442 in the messages, 10000 in the completion). Please reduce the length of the messages or completion.&#34;,\n    &#34;type&#34;: &#34;invalid_request_error&#34;,\n    &#34;param&#34;: &#34;messages&#34;,\n    &#34;code&#34;: &#34;context_length_exceeded&#34;\n  }\n}\n\nTrying again in 15 seconds.\n{&#39;error&#39;: {&#39;message&#39;: &#34;This model&#39;s maximum context length is 8192 tokens. However, you requested 10442 tokens (442 in the messages, 10000 in the completion). Please reduce the length of the messages or completion.&#34;, &#39;type&#39;: &#39;invalid_request_error&#39;, &#39;param&#39;: &#39;messages&#39;, &#39;code&#39;: &#39;context_length_exceeded&#39;}}\nERROR - Error in GPT response. Full response:\n{\n  &#34;error&#34;: {\n    &#34;message&#34;: &#34;This model&#39;s maximum context length is 8192 tokens. However, you requested 10442 tokens (442 in the messages, 10000 in the completion). Please reduce the length of the messages or completion.&#34;,\n    &#34;type&#34;: &#34;invalid_request_error&#34;,\n    &#34;param&#34;: &#34;messages&#34;,\n    &#34;code&#34;: &#34;context_length_exceeded&#34;\n  }\n}\n\nTrying again in 15 seconds.\n{&#39;error&#39;: {&#39;message&#39;: &#34;This model&#39;s maximum context length is 8192 tokens. However, you requested 10442 tokens (442 in the messages, 10000 in the completion). Please reduce the length of the messages or completion.&#34;, &#39;type&#39;: &#39;invalid_request_error&#39;, &#39;param&#39;: &#39;messages&#39;, &#39;code&#39;: &#39;context_length_exceeded&#39;}}\nERROR - Error in GPT response. Full response:\n{\n  &#34;error&#34;: {\n    &#34;message&#34;: &#34;This model&#39;s maximum context length is 8192 tokens. However, you requested 10442 tokens (442 in the messages, 10000 in the completion). Please reduce the length of the messages or completion.&#34;,\n    &#34;type&#34;: &#34;invalid_request_error&#34;,\n    &#34;param&#34;: &#34;messages&#34;,\n    &#34;code&#34;: &#34;context_length_exceeded&#34;\n  }\n}\n\nERROR - Error in populating requirement. GPT response could not be parsed as JSON. Asking GPT to correct response...\n</div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}}},{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">TypeError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-2059516999343069&gt;</span> in <span class=\"ansi-cyan-fg\">process_chunk</span><span class=\"ansi-blue-fg\">(content_type, index_chunk, chunk, output_dict, index_req, prompt, systemprompt, citation_prompt, templatename, df_control, df_results, df_errors, df_validation, fsd_lookup, bpd_lookup, transcripts_lookup, images_lookup, knowledge_base_docs, temperature, verbose, validation, backup_strict, log_id_doc)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    150</span>   <span class=\"ansi-green-fg\">try</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 151</span><span class=\"ansi-red-fg\">     </span>response_json <span class=\"ansi-blue-fg\">=</span> json<span class=\"ansi-blue-fg\">.</span>loads<span class=\"ansi-blue-fg\">(</span>response<span class=\"ansi-blue-fg\">,</span> strict<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-green-fg\">False</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    152</span>     print<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39; response_json:&#39;</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/usr/lib/python3.8/json/__init__.py</span> in <span class=\"ansi-cyan-fg\">loads</span><span class=\"ansi-blue-fg\">(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    340</span>         <span class=\"ansi-green-fg\">if</span> <span class=\"ansi-green-fg\">not</span> isinstance<span class=\"ansi-blue-fg\">(</span>s<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">(</span>bytes<span class=\"ansi-blue-fg\">,</span> bytearray<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 341</span><span class=\"ansi-red-fg\">             raise TypeError(f&#39;the JSON object must be str, bytes or bytearray, &#39;\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    342</span>                             f&#39;not {s.__class__.__name__}&#39;)\n\n<span class=\"ansi-red-fg\">TypeError</span>: the JSON object must be str, bytes or bytearray, not NoneType\n\nDuring handling of the above exception, another exception occurred:\n\n<span class=\"ansi-red-fg\">TypeError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-2059516999355172&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> generate_output_batch(df_control,\n</span><span class=\"ansi-green-intense-fg ansi-bold\">      2</span>                       df_results<span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span>                       df_mapping<span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      4</span>                       df_errors<span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      5</span>                       df_validation<span class=\"ansi-blue-fg\">,</span>\n\n<span class=\"ansi-green-fg\">&lt;command-2059516999343064&gt;</span> in <span class=\"ansi-cyan-fg\">generate_output_batch</span><span class=\"ansi-blue-fg\">(df_control, df_results, df_mapping, df_errors, df_validation, input_folder, index_fsd, index_bpd, index_transcripts, index_images, knowledge_base_docs, temperature, verbose, validation, backup_strict, citation, template_max_tokens_per_chunk, individual_sections, halt_on_errors)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     86</span>     <span class=\"ansi-red-fg\"># try:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     87</span>     <span class=\"ansi-green-fg\">if</span> <span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">---&gt; 88</span><span class=\"ansi-red-fg\">       process_document( index_req,\n</span><span class=\"ansi-green-intense-fg ansi-bold\">     89</span>                         row<span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     90</span>                         prompt<span class=\"ansi-blue-fg\">,</span>\n\n<span class=\"ansi-green-fg\">&lt;command-2059516999343066&gt;</span> in <span class=\"ansi-cyan-fg\">process_document</span><span class=\"ansi-blue-fg\">(index_req, row, prompt, systemprompt, citation_prompt, templatedict, defaulttemplatename, df_control, df_results, df_mapping, df_errors, df_validation, index_fsd, index_bpd, index_transcripts, index_images, knowledge_base_docs, temperature, verbose, validation, backup_strict, individual_sections)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    109</span>         <span class=\"ansi-red-fg\"># try:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    110</span>         <span class=\"ansi-green-fg\">if</span> <span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 111</span><span class=\"ansi-red-fg\">           process_func(content_type,\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    112</span>                         index_chunk<span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    113</span>                         chunk<span class=\"ansi-blue-fg\">,</span>\n\n<span class=\"ansi-green-fg\">&lt;command-2059516999343069&gt;</span> in <span class=\"ansi-cyan-fg\">process_chunk</span><span class=\"ansi-blue-fg\">(content_type, index_chunk, chunk, output_dict, index_req, prompt, systemprompt, citation_prompt, templatename, df_control, df_results, df_errors, df_validation, fsd_lookup, bpd_lookup, transcripts_lookup, images_lookup, knowledge_base_docs, temperature, verbose, validation, backup_strict, log_id_doc)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    154</span>   <span class=\"ansi-green-fg\">except</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    155</span>     print<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;ERROR - Error in populating requirement. GPT response could not be parsed as JSON. Asking GPT to correct response...&#34;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">--&gt; 156</span><span class=\"ansi-red-fg\">     </span>response<span class=\"ansi-blue-fg\">=</span>gpt35<span class=\"ansi-blue-fg\">(</span>prompt<span class=\"ansi-blue-fg\">=</span>fix_json_user_prompt<span class=\"ansi-blue-fg\">.</span>replace<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;{error_json}&#39;</span><span class=\"ansi-blue-fg\">,</span>response<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> context<span class=\"ansi-blue-fg\">=</span>fix_json_system_prompt<span class=\"ansi-blue-fg\">,</span> temperature<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">0</span><span class=\"ansi-blue-fg\">,</span> max_tokens<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">10000</span><span class=\"ansi-blue-fg\">,</span> large<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-green-fg\">True</span><span class=\"ansi-blue-fg\">,</span> tries<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">3</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    157</span>     <span class=\"ansi-green-fg\">try</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    158</span>       response_json <span class=\"ansi-blue-fg\">=</span> json<span class=\"ansi-blue-fg\">.</span>loads<span class=\"ansi-blue-fg\">(</span>response<span class=\"ansi-blue-fg\">,</span> strict<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-green-fg\">False</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-red-fg\">TypeError</span>: replace() argument 2 must be str, not None</div>"},"metadata":{"application/vnd.databricks.v1+output":{"arguments":{},"data":"<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">TypeError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-2059516999343069&gt;</span> in <span class=\"ansi-cyan-fg\">process_chunk</span><span class=\"ansi-blue-fg\">(content_type, index_chunk, chunk, output_dict, index_req, prompt, systemprompt, citation_prompt, templatename, df_control, df_results, df_errors, df_validation, fsd_lookup, bpd_lookup, transcripts_lookup, images_lookup, knowledge_base_docs, temperature, verbose, validation, backup_strict, log_id_doc)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    150</span>   <span class=\"ansi-green-fg\">try</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 151</span><span class=\"ansi-red-fg\">     </span>response_json <span class=\"ansi-blue-fg\">=</span> json<span class=\"ansi-blue-fg\">.</span>loads<span class=\"ansi-blue-fg\">(</span>response<span class=\"ansi-blue-fg\">,</span> strict<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-green-fg\">False</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    152</span>     print<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39; response_json:&#39;</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/usr/lib/python3.8/json/__init__.py</span> in <span class=\"ansi-cyan-fg\">loads</span><span class=\"ansi-blue-fg\">(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    340</span>         <span class=\"ansi-green-fg\">if</span> <span class=\"ansi-green-fg\">not</span> isinstance<span class=\"ansi-blue-fg\">(</span>s<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">(</span>bytes<span class=\"ansi-blue-fg\">,</span> bytearray<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 341</span><span class=\"ansi-red-fg\">             raise TypeError(f&#39;the JSON object must be str, bytes or bytearray, &#39;\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    342</span>                             f&#39;not {s.__class__.__name__}&#39;)\n\n<span class=\"ansi-red-fg\">TypeError</span>: the JSON object must be str, bytes or bytearray, not NoneType\n\nDuring handling of the above exception, another exception occurred:\n\n<span class=\"ansi-red-fg\">TypeError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-2059516999355172&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> generate_output_batch(df_control,\n</span><span class=\"ansi-green-intense-fg ansi-bold\">      2</span>                       df_results<span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span>                       df_mapping<span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      4</span>                       df_errors<span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      5</span>                       df_validation<span class=\"ansi-blue-fg\">,</span>\n\n<span class=\"ansi-green-fg\">&lt;command-2059516999343064&gt;</span> in <span class=\"ansi-cyan-fg\">generate_output_batch</span><span class=\"ansi-blue-fg\">(df_control, df_results, df_mapping, df_errors, df_validation, input_folder, index_fsd, index_bpd, index_transcripts, index_images, knowledge_base_docs, temperature, verbose, validation, backup_strict, citation, template_max_tokens_per_chunk, individual_sections, halt_on_errors)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     86</span>     <span class=\"ansi-red-fg\"># try:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     87</span>     <span class=\"ansi-green-fg\">if</span> <span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">---&gt; 88</span><span class=\"ansi-red-fg\">       process_document( index_req,\n</span><span class=\"ansi-green-intense-fg ansi-bold\">     89</span>                         row<span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     90</span>                         prompt<span class=\"ansi-blue-fg\">,</span>\n\n<span class=\"ansi-green-fg\">&lt;command-2059516999343066&gt;</span> in <span class=\"ansi-cyan-fg\">process_document</span><span class=\"ansi-blue-fg\">(index_req, row, prompt, systemprompt, citation_prompt, templatedict, defaulttemplatename, df_control, df_results, df_mapping, df_errors, df_validation, index_fsd, index_bpd, index_transcripts, index_images, knowledge_base_docs, temperature, verbose, validation, backup_strict, individual_sections)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    109</span>         <span class=\"ansi-red-fg\"># try:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    110</span>         <span class=\"ansi-green-fg\">if</span> <span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 111</span><span class=\"ansi-red-fg\">           process_func(content_type,\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    112</span>                         index_chunk<span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    113</span>                         chunk<span class=\"ansi-blue-fg\">,</span>\n\n<span class=\"ansi-green-fg\">&lt;command-2059516999343069&gt;</span> in <span class=\"ansi-cyan-fg\">process_chunk</span><span class=\"ansi-blue-fg\">(content_type, index_chunk, chunk, output_dict, index_req, prompt, systemprompt, citation_prompt, templatename, df_control, df_results, df_errors, df_validation, fsd_lookup, bpd_lookup, transcripts_lookup, images_lookup, knowledge_base_docs, temperature, verbose, validation, backup_strict, log_id_doc)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    154</span>   <span class=\"ansi-green-fg\">except</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    155</span>     print<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;ERROR - Error in populating requirement. GPT response could not be parsed as JSON. Asking GPT to correct response...&#34;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">--&gt; 156</span><span class=\"ansi-red-fg\">     </span>response<span class=\"ansi-blue-fg\">=</span>gpt35<span class=\"ansi-blue-fg\">(</span>prompt<span class=\"ansi-blue-fg\">=</span>fix_json_user_prompt<span class=\"ansi-blue-fg\">.</span>replace<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;{error_json}&#39;</span><span class=\"ansi-blue-fg\">,</span>response<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> context<span class=\"ansi-blue-fg\">=</span>fix_json_system_prompt<span class=\"ansi-blue-fg\">,</span> temperature<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">0</span><span class=\"ansi-blue-fg\">,</span> max_tokens<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">10000</span><span class=\"ansi-blue-fg\">,</span> large<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-green-fg\">True</span><span class=\"ansi-blue-fg\">,</span> tries<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">3</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    157</span>     <span class=\"ansi-green-fg\">try</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    158</span>       response_json <span class=\"ansi-blue-fg\">=</span> json<span class=\"ansi-blue-fg\">.</span>loads<span class=\"ansi-blue-fg\">(</span>response<span class=\"ansi-blue-fg\">,</span> strict<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-green-fg\">False</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-red-fg\">TypeError</span>: replace() argument 2 must be str, not None</div>","errorSummary":"<span class=\"ansi-red-fg\">TypeError</span>: replace() argument 2 must be str, not None","errorTraceType":"html","metadata":{},"type":"ipynbError"}}}]},{"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"2c1f2d90-34cb-43aa-8e79-02822c5ef175","showTitle":false,"title":""}},"cell_type":"markdown","source":"### 4b. Check control, result and error tables"},{"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"504e4096-79f3-4a42-942f-c700e67e3137","showTitle":false,"title":""},"trusted":false},"cell_type":"code","source":"df_control","execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"},"metadata":{"application/vnd.databricks.v1+output":{"arguments":{},"data":"","errorSummary":"Command skipped","errorTraceType":"html","metadata":{},"type":"ipynbError"}}}]},{"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"e5deb526-ca20-443e-8e36-d05217b22af6","showTitle":false,"title":""}},"cell_type":"markdown","source":"# Playground"},{"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"fce94bcb-b454-4157-8751-fe08c04ff6d5","showTitle":false,"title":""},"trusted":false},"cell_type":"code","source":"generate_output_batch(df_control,\n                      df_results,\n                      df_mapping,\n                      df_errors,\n                      df_validation,\n                      folder_input,\n                      index_fsd=index_fsd, #optional\n                      index_bpd=index_bpd, #optional\n                      index_transcripts=index_transcripts, #optional\n                      # index_images=index_images, #optional\n                      # knowledge_base_docs=knowledge_base, #optional\n                      verbose=False, # True will output all prompts as well as all placeholder replacements in the doc\n                      validation = True, # true will store chunks prompt and response in df_validation \n                      citation=False, # True will cite instances where information is referenced\n                      template_max_tokens_per_chunk=400,\n                      individual_sections=False, # experimental - use one prompt for each placeholder (instead of chunking them together). use False for default flow!\n                      halt_on_errors = False\n                      )","execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"},"metadata":{"application/vnd.databricks.v1+output":{"arguments":{},"data":"","errorSummary":"Command skipped","errorTraceType":"html","metadata":{},"type":"ipynbError"}}}]},{"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"07321aa4-e501-4b5e-95d1-7d8010266b49","showTitle":false,"title":""}},"cell_type":"markdown","source":"### Validation section"},{"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"76e76be4-026f-49e2-9a4a-553221e36e56","showTitle":false,"title":""},"trusted":false},"cell_type":"code","source":"db_ws.ListFiles()","execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"},"metadata":{"application/vnd.databricks.v1+output":{"arguments":{},"data":"","errorSummary":"Command skipped","errorTraceType":"html","metadata":{},"type":"ipynbError"}}}]},{"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"5285662f-9dd5-4c8b-b387-bc766597a237","showTitle":false,"title":""},"trusted":false},"cell_type":"code","source":"oldfile1='''OGE_FSD_NH-E_PA_003_IM Program Position $ to WBS $_2023-08-03_22_32_30.docx'''\noldfile2='''OGE_FSD_NH-E_PA_002_IM Program $ to IM Program Position $_2023-08-03_22_19_40.docx'''\n\nnewfile1='''OGE_FSD_NH-E_PA_003_IM Program Position $ to WBS $_2023-08-03_23_03_26.docx'''\nnewfile2='''OGE_FSD_NH-E_PA_002_IM Program $ to IM Program Position $_2023-08-03_22_47_44.docx'''\n\nout1 = '''OGE_FSD_IN-I_WAM_T&D_012_T&D Integration - ArcGIS Online Inspection Results to create SAP Measurement Results_2023-10-11_03_57_30.docx'''\n\nout2 = '''OGE_FSD_IN-I_FIN_001_Ability to send Positive Pay file to Bank of OK for check details._2023-10-11_14_26_00.docx'''\nval2 = '''OGE_FSD_IN-I_FIN_001_Ability to send Positive Pay file to Bank of OK for check details._2023-06-14_01_13_32.docx'''\n\nout3 = '''OGE_FSD_IN-E_SCM_029_Expeditor Notes Field_2023-10-11_21_18_23.docx'''\nval3 = '''OGE_FSD_IN-E_SCM_029_Expeditor Notes Field_2023-06-14_01_04_44.docx'''\n#new name with files i genrated todays date\n#what to change name to is new file whats generated","execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"},"metadata":{"application/vnd.databricks.v1+output":{"arguments":{},"data":"","errorSummary":"Command skipped","errorTraceType":"html","metadata":{},"type":"ipynbError"}}}]},{"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"87ad4e01-597d-4837-ae01-8c84a99d5083","showTitle":false,"title":""},"trusted":false},"cell_type":"code","source":"db_ws.CopyFileFromWorkbench(DatabricksFolder='file:/tmp/SAP',filename=oldfile1)\ndb_ws.CopyFileFromWorkbench(DatabricksFolder='file:/tmp/SAP',filename=oldfile2)\ndb_ws.CopyFileFromWorkbench(DatabricksFolder='file:/tmp/SAP',filename=newfile1)\ndb_ws.CopyFileFromWorkbench(DatabricksFolder='file:/tmp/SAP',filename=newfile2)","execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"},"metadata":{"application/vnd.databricks.v1+output":{"arguments":{},"data":"","errorSummary":"Command skipped","errorTraceType":"html","metadata":{},"type":"ipynbError"}}}]},{"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"5b9fc242-64c9-4008-ac3b-31387e3d7427","showTitle":false,"title":""},"trusted":false},"cell_type":"code","source":"# db_ws.CopyFileFromWorkbench(DatabricksFolder='file:/tmp/SAP',filename='DNU_OGE_FSD_E_PA_003_IM Program Position $ to WBS $.docx') \ndb_ws.CopyFileFromWorkbench(DatabricksFolder='file:/tmp/SAP',filename=val3) \ndb_ws.CopyFileFromWorkbench(DatabricksFolder='file:/tmp/SAP',filename=out3) \ndbutils.fs.ls('file:/tmp/SAP')","execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"},"metadata":{"application/vnd.databricks.v1+output":{"arguments":{},"data":"","errorSummary":"Command skipped","errorTraceType":"html","metadata":{},"type":"ipynbError"}}}]},{"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"ece129a4-2b72-4592-96c0-26f44a96f96a","showTitle":false,"title":""},"trusted":false},"cell_type":"code","source":"# validated_df = validate_docs('DNU_OGE_FSD_E_PA_003_IM Program Position $ to WBS $.docx', oldfile1, verbose = True)\nvalidated_df = validate_docs(val3, out3, verbose = True)\nWBS_preindex_cleaned_df = cleanup_dupes(validated_df)\nWBS_preindex_cleaned_df.plot.bar(y='cos_sim')\n#why team one\n\nWBS_preindex_mean = WBS_preindex_cleaned_df['cos_sim'].mean()\nprint(WBS_preindex_mean)","execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"},"metadata":{"application/vnd.databricks.v1+output":{"arguments":{},"data":"","errorSummary":"Command skipped","errorTraceType":"html","metadata":{},"type":"ipynbError"}}}]},{"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"c122aaed-691b-4968-9d24-780cd0efe2c0","showTitle":false,"title":""},"trusted":false},"cell_type":"code","source":"# 3k = 10 run\nvalidated_df = validate_docs('DNU_OGE_FSD_E_PA_003_IM Program Position $ to WBS $.docx', newfile1, verbose = True)\nWBS_k10_cleaned_df = cleanup_dupes(validated_df)\nWBS_k10_cleaned_df.plot.bar(y='cos_sim')\n\nWBS_k10_mean = WBS_k10_cleaned_df['cos_sim'].mean()\nprint(WBS_k10_mean)","execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"},"metadata":{"application/vnd.databricks.v1+output":{"arguments":{},"data":"","errorSummary":"Command skipped","errorTraceType":"html","metadata":{},"type":"ipynbError"}}}]},{"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"a02e6f8a-3c0b-44a9-890f-c5ddc43c3508","showTitle":false,"title":""},"trusted":false},"cell_type":"code","source":"WBS_preindex_cleaned_df","execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"},"metadata":{"application/vnd.databricks.v1+output":{"arguments":{},"data":"","errorSummary":"Command skipped","errorTraceType":"html","metadata":{},"type":"ipynbError"}}}]},{"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"5fd72309-62a3-4c30-9e13-b82e4458bb98","showTitle":false,"title":""},"trusted":false},"cell_type":"code","source":"print('pre index average ' + str(WBS_preindex_mean) + ' post index average ' + str(WBS_k10_mean))","execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"},"metadata":{"application/vnd.databricks.v1+output":{"arguments":{},"data":"","errorSummary":"Command skipped","errorTraceType":"html","metadata":{},"type":"ipynbError"}}}]},{"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"01bfab30-e20c-416b-8a85-2469c73ecb52","showTitle":false,"title":""},"trusted":false},"cell_type":"code","source":"db_ws.CopyFileFromWorkbench(DatabricksFolder='file:/tmp/SAP',filename='DNU_OGE_FSD_E_PA_002_IM Program $ to IM Program Position $.docx')","execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"},"metadata":{"application/vnd.databricks.v1+output":{"arguments":{},"data":"","errorSummary":"Command skipped","errorTraceType":"html","metadata":{},"type":"ipynbError"}}}]},{"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"ca40f31a-94d8-432a-8948-4326b273cecf","showTitle":false,"title":""},"trusted":false},"cell_type":"code","source":"# pre bpd\n\nvalidated_df = validate_docs('DNU_OGE_FSD_E_PA_002_IM Program $ to IM Program Position $.docx', oldfile2, verbose = True)\nIMP_pre_cleaned_df = cleanup_dupes(validated_df)\nIMP_pre_cleaned_df.plot.bar(y='cos_sim')\n\nIMP_pre_mean = IMP_pre_cleaned_df['cos_sim'].mean()\nprint(IMP_pre_mean)","execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"},"metadata":{"application/vnd.databricks.v1+output":{"arguments":{},"data":"","errorSummary":"Command skipped","errorTraceType":"html","metadata":{},"type":"ipynbError"}}}]},{"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"88deb09a-628a-41dc-959b-4f47fe396c3d","showTitle":false,"title":""},"trusted":false},"cell_type":"code","source":"#k = 10 run\nvalidated_df = validate_docs('DNU_OGE_FSD_E_PA_002_IM Program $ to IM Program Position $.docx', newfile2, verbose = True)\nIMP_k10_cleaned_df = cleanup_dupes(validated_df)\nIMP_k10_cleaned_df.plot.bar(y='cos_sim')\n\nIMP_k10_mean = IMP_k10_cleaned_df['cos_sim'].mean()\nprint(IMP_k10_mean)","execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"},"metadata":{"application/vnd.databricks.v1+output":{"arguments":{},"data":"","errorSummary":"Command skipped","errorTraceType":"html","metadata":{},"type":"ipynbError"}}}]},{"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"afd1f290-62f1-4087-8854-b2540d20c103","showTitle":false,"title":""},"trusted":false},"cell_type":"code","source":"print('pre bpd score' + str(IMP_pre_mean) + ' post bpd score ' + str(IMP_k10_mean))","execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"},"metadata":{"application/vnd.databricks.v1+output":{"arguments":{},"data":"","errorSummary":"Command skipped","errorTraceType":"html","metadata":{},"type":"ipynbError"}}}]},{"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"82fc66f7-4b24-4a96-bba3-578ab4c5b4c6","showTitle":false,"title":""},"trusted":false},"cell_type":"code","source":"IMP_k10_cleaned_df","execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"},"metadata":{"application/vnd.databricks.v1+output":{"arguments":{},"data":"","errorSummary":"Command skipped","errorTraceType":"html","metadata":{},"type":"ipynbError"}}}]},{"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"12c34978-8f30-411d-9ae7-21bae62628b2","showTitle":false,"title":""},"trusted":false},"cell_type":"code","source":"%ls /tmp/SAP/","execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"},"metadata":{"application/vnd.databricks.v1+output":{"arguments":{},"data":"","errorSummary":"Command skipped","errorTraceType":"html","metadata":{},"type":"ipynbError"}}}]},{"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"cdbc4a5d-fcb7-4961-b1f1-81e464472859","showTitle":false,"title":""},"trusted":false},"cell_type":"code","source":"IMP_k10_cleaned_df.loc['Security and controls']['Sections_source']","execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"},"metadata":{"application/vnd.databricks.v1+output":{"arguments":{},"data":"","errorSummary":"Command skipped","errorTraceType":"html","metadata":{},"type":"ipynbError"}}}]},{"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"d76fe183-7c3e-4b3e-a679-b4eb4ff4b18b","showTitle":false,"title":""},"trusted":false},"cell_type":"code","source":"IMP_k10_cleaned_df.loc['Security and controls']['Sections_generated']","execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"},"metadata":{"application/vnd.databricks.v1+output":{"arguments":{},"data":"","errorSummary":"Command skipped","errorTraceType":"html","metadata":{},"type":"ipynbError"}}}]},{"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"628f4735-3748-49f2-a804-e2bf046fb25d","showTitle":false,"title":""},"trusted":false},"cell_type":"code","source":"IMP_k10_cleaned_df.loc['Testing Scenarios & Steps']['Sections_source']","execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"},"metadata":{"application/vnd.databricks.v1+output":{"arguments":{},"data":"","errorSummary":"Command skipped","errorTraceType":"html","metadata":{},"type":"ipynbError"}}}]},{"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"da589252-18d1-4bcc-b754-043ed8345381","showTitle":false,"title":""},"trusted":false},"cell_type":"code","source":"IMP_k10_cleaned_df.loc['Testing Scenarios & Steps']['Sections_generated']","execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"},"metadata":{"application/vnd.databricks.v1+output":{"arguments":{},"data":"","errorSummary":"Command skipped","errorTraceType":"html","metadata":{},"type":"ipynbError"}}}]},{"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"00ee89ae-8654-4c64-ba81-75ddadd5017a","showTitle":false,"title":""},"trusted":false},"cell_type":"code","source":"## what would the similarity of one of these sections be if we word soup this?\n\nmodel = sentence_transformers.SentenceTransformer(\"sentence-transformers/bert-base-nli-mean-tokens\")\n\nWBS_k10_cleaned_df.loc['Requirement description']['Sections_generated']\n\nimport random\n\ndef rearrange_words(string):\n    words = string.split()\n    random.shuffle(words)\n    return \" \".join(words)\n\nstring = WBS_k10_cleaned_df.loc['Requirement description']['Sections_generated']\nnew_string = rearrange_words(string)\n\n\nsource_embedding= model.encode(WBS_k10_cleaned_df.loc['Requirement description']['Sections_source'], convert_to_tensor=True)\ngen_embedding = model.encode(new_string, convert_to_tensor=True)\nnew_score =  util.pytorch_cos_sim(source_embedding, gen_embedding).tolist()[0][0]\n\nprint(new_string)","execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"},"metadata":{"application/vnd.databricks.v1+output":{"arguments":{},"data":"","errorSummary":"Command skipped","errorTraceType":"html","metadata":{},"type":"ipynbError"}}}]},{"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"7fbb8b42-9165-45be-b1df-817c8cfea768","showTitle":false,"title":""},"trusted":false},"cell_type":"code","source":"local_save_folder = \"/tmp/SAP/\"\n# doc, placeholder, originalposition = read_document(local_save_folder+ 'DNU_OGE_FSD_E_PA_002_IM Program $ to IM Program Position $.docx')\ndoc = Document(local_save_folder+ 'DNU_OGE_FSD_E_PA_002_IM Program $ to IM Program Position $.docx')\n\nfor paragraph in doc.paragraphs:\n  if paragraph.text != '':\n    print(paragraph.text)\n  else:\n    print(paragraph)","execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":"<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"},"metadata":{"application/vnd.databricks.v1+output":{"arguments":{},"data":"","errorSummary":"Command skipped","errorTraceType":"html","metadata":{},"type":"ipynbError"}}}]},{"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"60c2097d-6b94-4cea-91ca-51932288eac8","showTitle":false,"title":""},"trusted":false},"cell_type":"code","source":"","execution_count":0,"outputs":[]}],"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[],"language":"python","notebookMetadata":{"mostRecentlyExecutedCommandWithImplicitDF":{"commandId":-1,"dataframes":["_sqldf"]},"pythonIndentUnit":2},"notebookName":"SAP_FDD_RunLoop","widgets":{}},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}