{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a048ce89-714d-4329-8daf-5d01d0533a96",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Preprocessing Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f23e712f-0749-4617-a828-a320005d9fc0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Requirements Filents, filename_requirements):\n",
    "def get_df_requirements(folder_input, filename_requirements):\n",
    "  if not os.path.exists(folder_input):\n",
    "    os.makedirs(folder_input)\n",
    "  db_ws.CopyFileFromWorkbench(DatabricksFolder=\"file:\"+folder_input, filename=filename_requirements)\n",
    "  df_requirements=pd.read_excel(folder_input+filename_requirements, engine='openpyxl')\n",
    "  # remove faulty entries\n",
    "  df_requirements = df_requirements[df_requirements[\"RICEFW Name\"].map(len) >= 4].reset_index(drop=True)\n",
    "\n",
    "  df_requirements_clean=df_requirements.fillna('')\n",
    "  conditions = [\n",
    "      (df_requirements_clean['RICEFW Name'].str.strip().str.lower() == df_requirements_clean['RICEFW Description'].str.strip().str.lower())]\n",
    "  choices = [df_requirements_clean['RICEFW Name']]\n",
    "  df_requirements_clean['Requirement Cleansed']=np.select(conditions, choices, df_requirements_clean['RICEFW Name'].str.strip()+': '+df_requirements_clean['RICEFW Description'].str.strip())\n",
    "  # df_requirements_clean['Detailed Description'].fillna('',inplace=True)\n",
    "  df_requirements_clean['Requirement Generalized'] = df_requirements_clean['RICEFW Name'] # default, if generalization is not run\n",
    "  return df_requirements_clean\n",
    "  \n",
    "## Mapping File\n",
    "def get_df_mapping(folder_mapping, filename_mapping):\n",
    "  if not os.path.exists(folder_mapping):\n",
    "    os.makedirs(folder_mapping)\n",
    "  db_ws.CopyFileFromWorkbench(DatabricksFolder=\"file:\"+folder_mapping, filename=filename_mapping)\n",
    "  df_mapping=pd.read_excel(folder_mapping+filename_mapping)\n",
    "  df_mapping=df_mapping[df_mapping['Requirement Type'].notna()]\n",
    "  return df_mapping\n",
    "\n",
    "## Compile result table & control table for batch processing\n",
    "def get_df_control(df_requirements):\n",
    "  df_control = df_requirements.copy()\n",
    "  df_control[\"Transcripts Lookup\"] = \"\"\n",
    "  df_control[\"FSD Lookup\"] = \"\"\n",
    "  df_control[\"BPD Lookup\"] = \"\"\n",
    "  df_control[\"Images Lookup\"] = \"\"\n",
    "  df_control[\"Template\"] = \"\"\n",
    "  df_control[\"Outfile\"] = \"\"\n",
    "  df_control[\"LastChunk_contenttype\"] = \"\"\n",
    "  df_control[\"LastChunk_index\"] = -1\n",
    "  return df_control\n",
    "\n",
    "def get_df_results(df_requirements):\n",
    "  df_results = df_requirements.copy()[[\"RICEFW ID\", \"RICEFW Name\"]]\n",
    "  df_results[\"JSON\"] = \"\"\n",
    "  return df_results\n",
    "\n",
    "def get_df_errors():\n",
    "  df_errors = pd.DataFrame(columns=['RICEFW ID', 'RICEFW Name', 'LastChunk_contenttype', 'LastChunk_index', 'response'])\n",
    "  return df_errors\n",
    "\n",
    "def get_df_validation():\n",
    "  df_results = pd.DataFrame(columns = [\"RICEFW ID\", \"RICEFW Name\", \"Chunk Numb\", \"Prompt\", \"Response\", \"Cos Sim Score\", \"GPT suggestions\"])\n",
    "  return df_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35a8a835-19de-4e37-8cab-b18d198b51ff",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6511dfa4-f47c-4e63-aadc-026822522e2e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def lookup_in_index(index_type,\n",
    "                    index,\n",
    "                    req_search_term,\n",
    "                    req_search_count,\n",
    "                    df_control,\n",
    "                    requirement_id,\n",
    "                    log_id_doc):\n",
    "  \n",
    "  # Determine which type of lookup will be performed\n",
    "  if index_type.lower() == \"transcript\" or index_type.lower() == \"transcripts\":\n",
    "    index_type_str = \"transcripts\"\n",
    "    index_type_column_str = \"Transcripts Lookup\"\n",
    "  elif index_type.lower() == \"fsd\" or index_type.lower() == \"fsds\":\n",
    "    index_type_str = \"FSDs\"\n",
    "    index_type_column_str = \"FSD Lookup\"\n",
    "  elif index_type.lower() == \"bpd\" or index_type.lower() == \"bpds\":\n",
    "    index_type_str = \"BPDs\"\n",
    "    index_type_column_str = \"BPD Lookup\"\n",
    "  elif index_type.lower() == \"image\" or index_type.lower() == \"images\":\n",
    "    index_type_str = \"images\"\n",
    "    index_type_column_str = \"Images Lookup\"\n",
    "\n",
    "  ## Get requirement transcripts references from vector store\n",
    "  if index != None:\n",
    "    if df_control.loc[requirement_id, index_type_column_str] == \"\":\n",
    "      ## Whoosh approach\n",
    "      if isinstance(index, DocumentIndexWhoosh):\n",
    "        log(f\"[{log_id_doc}] Looking up requirement in the {index_type_str} index via Whoosh ... \")\n",
    "        lookup_result=index.search_and_summarize(req_search_term)\n",
    "        df_control.loc[requirement_id, index_type_column_str] = lookup_result\n",
    "        log(f\"[{log_id_doc}] Looking up requirement in the {index_type_str} index via Whoosh ... done.\")       \n",
    "      elif isinstance(index, RetrievalQA):\n",
    "        ## Langchain (FAISS) approach\n",
    "        log(f\"[{log_id_doc}] Looking up requirement in the {index_type_str} index via FAISS ... \")\n",
    "        prompt = f\"\"\"What information can be leveraged to build the below requirement? Also list the names of the meetings/documents you took the information from. Requirement: \\n\\n'{req_search_term}'\"\"\"\n",
    "        lookup_result=index.run(prompt)\n",
    "        df_control.loc[requirement_id, index_type_column_str] = lookup_result\n",
    "        log(f\"[{log_id_doc}] Looking up requirement in the {index_type_str} index via FAISS ... done.\")\n",
    "      elif isinstance(index, CombinedIndex):\n",
    "        ## CombinedIndex approach\n",
    "        log(f\"[{log_id_doc}] Looking up requirement in the {index_type_str} index via the combined Whoosh, FAISS & GPT approach ... \")\n",
    "        lookup_result=index.search_and_summarize(req_search_term, k=req_search_count)\n",
    "        df_control.loc[requirement_id, index_type_column_str] = lookup_result\n",
    "        log(f\"[{log_id_doc}] Looking up requirement in the {index_type_str} index via the combined Whoosh, FAISS & GPT approach ... done\")\n",
    "      elif isinstance(index, DocumentIndexACS_v2):\n",
    "        ## ACS approach\n",
    "        log(f\"[{log_id_doc}] Looking up requirement in the {index_type_str} index via the ACS approach ... \")\n",
    "        lookup_result=index.search_and_summarize(req_search_term, k=req_search_count, mode=\"hybrid\")\n",
    "        df_control.loc[requirement_id, index_type_column_str] = lookup_result\n",
    "        log(f\"[{log_id_doc}] Looking up requirement in the {index_type_str} index via the ACS approach ... done\")\n",
    "      ### TODO - Section for langchain ACS indexes\n",
    "      # elif isinstance(index, AzureSearchRetriever?):\n",
    "      #   log(f\"[{log_id_doc}] Looking up requirement in the {index_type_str} index via the Langchain ACS approach ... \")\n",
    "      #   lookup_result= ... query the index using hybrid mode, filter on correct group_id\n",
    "      #   df_control.loc[requirement_id, index_type_column_str] = lookup_result\n",
    "      #   log(f\"[{log_id_doc}] Looking up requirement in the {index_type_str} index via the Langchain ACS approach ... done\")\n",
    "      ############\n",
    "      else:\n",
    "        log(f\"[{log_id_doc}] {index_type_str} index is of unsupported type: '{str(type(index))}'. Please use either whoosh (DocumentIndexWhoosh), langchain (RetrievalQA), ACS (DocumentIndexACS_v2) or the custom combined index (CombinedIndex)\")\n",
    "        raise Exception(f\"Unsupported {index_type_str} index type\")\n",
    "    else:\n",
    "      log(f\"[{log_id_doc}] {index_type_str} lookup results already set in Control Table. Using this vaule and skipping to next step.\")\n",
    "      lookup_result = df_control.loc[requirement_id, index_type_column_str]\n",
    "  else:\n",
    "    log(f\"[{log_id_doc}] No index for {index_type_str} provided. Skipping the lookup step.\")\n",
    "    lookup_result = None\n",
    "  \n",
    "  return lookup_result\n",
    "\n",
    "def backup(df, backup_path=\"tmp_SAP_Control_Table_Backup.csv\"):\n",
    "  df.to_csv(backup_path)\n",
    "\n",
    "def retrieve(backup_path=\"tmp_SAP_Control_Table_Backup.csv\"):\n",
    "  return pd.read_csv(backup_path).fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91b50f44-9612-479d-a3d9-8f812caa6a1e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Core Logic (generate content for docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71634bfb-5da7-49a5-8745-adae523a0e21",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Control level loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9dde678-70db-4604-8ade-d0d3e6244a6e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#########################################\n",
    "#      Core Logic (batch processing)    #\n",
    "#########################################\n",
    "\n",
    "#@keep_trying \n",
    "def generate_output_batch(df_control,\n",
    "                          df_results,\n",
    "                          df_mapping,\n",
    "                          df_errors,\n",
    "                          df_validation,\n",
    "                          input_folder,\n",
    "                          index_fsd=None,\n",
    "                          index_bpd=None,\n",
    "                          index_transcripts=None,\n",
    "                          index_images=None,\n",
    "                          knowledge_base_docs=None,\n",
    "                          temperature=0,\n",
    "                          verbose=False,\n",
    "                          validation= False,\n",
    "                          backup_strict=True,\n",
    "                          citation=False,\n",
    "                          template_max_tokens_per_chunk=800,\n",
    "                          individual_sections=False,\n",
    "                          halt_on_errors = False):\n",
    "\n",
    "  ## Prompts and context\n",
    "  projectbackground = \"This project is an SAP S4 transformation focusing on finance for Oklahoma Gas and Electric Company (OGE), using SAP's fit to standard approach.\"\n",
    "\n",
    "  systemprompt = \"You specialize in writing content for Functional Specification Documents for projects. \" + projectbackground\n",
    "\n",
    "  if citation==False:\n",
    "    citation_prompt=''\n",
    "  else:\n",
    "    citation_prompt=', end element content with <transref> if and only when useful info is referenced from workshop transcript'\n",
    "\n",
    "  prompt = \"\"\"\n",
    "  ### Start of Requirement Info\n",
    "  Requirement: '{requirement}'\n",
    "  RICEFW Type='{RICEFWType}'\n",
    "  RICEFW ID='{RICEFWID}'\n",
    "  RICEFW Name='{RICEFWName}'\n",
    "  Requirement detailed description: \n",
    "  ```\n",
    "  {requirement_detailed_description}\n",
    "  ```\n",
    "  {transcripts_lookup}\n",
    "  {bpd_lookup}\n",
    "  {fsd_lookup}\n",
    "  {knowledge_base_docs}\n",
    "  ### End of Requirement Info\n",
    "\n",
    "  Response must follow rules: Do not change the schema of the JSON template in any way, never add or remove any elements in it, ensure 'placeholder_text' element is always present before each 'replacement_text' element\n",
    "\n",
    "  Based on the requirement info above, populate detailed content for the 'replacement_text' elements in the following JSON template by including all relevant granular details that can be referenced (should be lengthy paragraphs instead of one liners, use bullet points where necessary, customize based on input requirement{citation_prompt}) by referencing instructions in the corresponding 'placeholder_text' elements (but never copy from it as is, always have your own perspective, back it up with detailed explanations and scenarios/examples), also refer to corresponding 'section_header' values for additional context, the data type of the 'replacement_text' elements must be text, your response MUST be only the updated JSON template and nothing else, ensure character escape is implemented where applicable so that json.loads() can read your response, do not change the schema of the JSON template in any way, never add or remove any elements in it, ensure 'placeholder_text' element is always present before each 'replacement_text' element:\n",
    "\n",
    "  {jsontemplate}\n",
    "  \"\"\"\n",
    "\n",
    "  ### Exit Criteria for running this func in loop\n",
    "  exit_crit = \"\" not in df_control[\"Outfile\"].values # will be True if all documents have been created\n",
    "  if exit_crit:\n",
    "    log(\"SUCCESS - All documents have been generated. Exiting now.\", color=\"green\")\n",
    "    return True\n",
    "\n",
    "  ### Optional parameters handling\n",
    "  \n",
    "  if index_fsd == None:\n",
    "    log(\"[Main] WARNING - Index for reference FSDs not provided. Model will ignore reference FSDs. Pass it to the main function with the 'index_fsd' argument.\", color=\"bold\")\n",
    "\n",
    "  if index_bpd == None:\n",
    "    log(\"[Main] WARNING - Index for BPDs not provided. Model will ignore BPDs. Pass it to the main function with the 'index_bpd' argument.\", color=\"bold\")\n",
    "\n",
    "  if index_transcripts == None:\n",
    "    log(\"[Main] WARNING - Index for workshop transcripts not provided. Model will ignore workshop transcripts. Pass it to the main function with the 'index_transcripts' argument.\", color=\"bold\")\n",
    "  \n",
    "  if knowledge_base_docs == None:\n",
    "    log(\"[Main] WARNING - Knowledge Base for Input FSDs is not set. Pass it to the main function with the 'knowledge_base_docs' argument.\", color=\"bold\")\n",
    "  \n",
    "  ### Refresh template dict\n",
    "  log(f\"[Main] Parsing templates\")\n",
    "  templatedict = read_templates(input_folder, max_tokens_per_chunk=template_max_tokens_per_chunk)\n",
    "  defaulttemplatename='OGE_Functional Specification Document Template__Approved'\n",
    "\n",
    "  ### Iterate through all requirements in df_control\n",
    "  for index_req,row in df_control.iterrows():\n",
    "    # try:\n",
    "    if 1:\n",
    "      process_document( index_req,\n",
    "                        row,\n",
    "                        prompt,\n",
    "                        systemprompt,\n",
    "                        citation_prompt,\n",
    "                        templatedict,\n",
    "                        defaulttemplatename,\n",
    "                        df_control,\n",
    "                        df_results,\n",
    "                        df_mapping,\n",
    "                        df_errors,\n",
    "                        df_validation,\n",
    "                        index_fsd,\n",
    "                        index_bpd,\n",
    "                        index_transcripts,\n",
    "                        index_images,\n",
    "                        knowledge_base_docs,\n",
    "                        temperature,\n",
    "                        verbose,\n",
    "                        validation,\n",
    "                        backup_strict,\n",
    "                        individual_sections)\n",
    "    # except Exception as err:\n",
    "    #   # Skip to next document\n",
    "    #   log(\"ERROR - Error in populating FSD for this requirement. Skipping to next requirement.\", color=\"red\")\n",
    "    #   print(\"Traceback:\")\n",
    "    #   if halt_on_errors: raise err # for DEBUG mode - will raise the actual error and halt execution\n",
    "    #   else: print(err) # for RUN mode - will skip over the error and continue with the next requirement\n",
    "    #   continue\n",
    "\n",
    "  ### Exit Criteria for running this func in loop\n",
    "  exit_crit = \"\" not in df_control[\"Outfile\"].values # will be True if all documents have been created\n",
    "  if exit_crit:\n",
    "    log(\"SUCCESS - All documents have been generated. Exiting now.\", color=\"green\")\n",
    "    return True\n",
    "  else:\n",
    "    return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c18a507-ba1a-4cae-a85d-97e0766a3823",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Document level loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7423c100-a1c7-4ffa-b6e6-d69782ef62fa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def process_document( index_req,\n",
    "                      row,\n",
    "                      prompt,\n",
    "                      systemprompt,\n",
    "                      citation_prompt,\n",
    "                      templatedict,\n",
    "                      defaulttemplatename,\n",
    "                      df_control,\n",
    "                      df_results,\n",
    "                      df_mapping,\n",
    "                      df_errors,\n",
    "                      df_validation,\n",
    "                      index_fsd,\n",
    "                      index_bpd,\n",
    "                      index_transcripts,\n",
    "                      index_images,\n",
    "                      knowledge_base_docs,\n",
    "                      temperature,\n",
    "                      verbose,\n",
    "                      validation,\n",
    "                      backup_strict,\n",
    "                      individual_sections):\n",
    "  \n",
    "  # For logging the current document number (and total document count)\n",
    "  log_id_doc = f\"Document {index_req+1}/{len(df_control)}\"\n",
    "\n",
    "  log(f\"[{log_id_doc}] Processing Requirement : {row['RICEFW ID']} ({row['RICEFW Name']})\")\n",
    "\n",
    "  if df_control.loc[index_req, \"Outfile\"] != \"\":\n",
    "    log(f\"[{log_id_doc}] Files for requirement already written to workbench ('{df_control.loc[index_req, 'Outfile']}'). Skipping to next requirement.\", color=\"green\")\n",
    "    return\n",
    "\n",
    "  ## Get template for current requirement, looking it up in the mapping df\n",
    "  if df_control.loc[index_req, \"Template\"] == \"\":\n",
    "    calctemplatename=df_mapping.loc[df_mapping['Requirement Type'].str.strip().str.lower()==row['RICEFW Type'].strip().lower(),'Template Name']\n",
    "    if len(calctemplatename)>0:\n",
    "      templatename=calctemplatename.values[0]\n",
    "    else:\n",
    "      templatename = defaulttemplatename\n",
    "    df_control.loc[index_req, \"Template\"] = templatename\n",
    "  else:\n",
    "    log(f\"[{log_id_doc}] Template already set in Control Table. Using this value ('{df_control.loc[index_req, 'Template']}') and skipping to next step.\")\n",
    "    templatename = df_control.loc[index_req, \"Template\"]\n",
    "\n",
    "  log(\" checkpoint 1 \")\n",
    "  ### Lookups in thrious indexes\n",
    "  req_search_term=(row['Requirement Cleansed']+'\\n\\n'+row['Detailed Description']).rstrip('\\n\\n')\n",
    "  req_search_count=10\n",
    "\n",
    "  ## Get transcripts references from vector store\n",
    "  transcripts_lookup = None\n",
    "  if index_transcripts != None:\n",
    "    transcripts_lookup = lookup_in_index(\"transcripts\",\n",
    "                                          index_transcripts,\n",
    "                                          req_search_term,\n",
    "                                          req_search_count,\n",
    "                                          df_control,\n",
    "                                          index_req,\n",
    "                                          log_id_doc)\n",
    "\n",
    "  ## Get FSD references from vector store\n",
    "  fsd_lookup = None\n",
    "  if index_fsd != None:\n",
    "    fsd_lookup = lookup_in_index(\"fsd\",\n",
    "                                  index_fsd,\n",
    "                                  req_search_term,\n",
    "                                  req_search_count,\n",
    "                                  df_control,\n",
    "                                  index_req,\n",
    "                                  log_id_doc)\n",
    "\n",
    "  ## Get BPD references from vector store\n",
    "  bpd_lookup = None\n",
    "  if index_bpd != None:\n",
    "    bpd_lookup = lookup_in_index(\"bpd\",\n",
    "                                  index_bpd,\n",
    "                                  req_search_term,\n",
    "                                  req_search_count,\n",
    "                                  df_control,\n",
    "                                  index_req,\n",
    "                                  log_id_doc)\n",
    "\n",
    "  ## Get Images (flowcharts, screenshots, ...) references from vector store\n",
    "  images_lookup = None\n",
    "  if index_images != None:\n",
    "    images_lookup = lookup_in_index(\"images\",\n",
    "                                  index_images,\n",
    "                                  req_search_term,\n",
    "                                  req_search_count,\n",
    "                                  df_control,\n",
    "                                  index_req,\n",
    "                                  log_id_doc)\n",
    "\n",
    "  ## Get latest version of the JSON output or initiate a fresh one from the corresponding template\n",
    "  output_dict = {}\n",
    "  if df_results.loc[index_req, \"JSON\"] == \"\":\n",
    "    output_dict = deepcopy(templatedict[templatename][\"placeholders\"])\n",
    "    df_results.loc[index_req, \"JSON\"] = json.dumps(output_dict)\n",
    "  else:\n",
    "    log(f\"[{log_id_doc}] Output JSON already present in Results Table -> output generation has already started. Continuing at latest chunk.\")\n",
    "    output_dict = json.loads(df_results.loc[index_req, \"JSON\"], strict=False)\n",
    "\n",
    "  for content_type in [\"paragraphs\", \"tables\"]:\n",
    "    if output_dict[content_type][\"chunks\"]!=[[]]:\n",
    "      for index_chunk, chunk in enumerate(output_dict[content_type][\"chunks\"]):\n",
    "        # swap out the processing method based on the individual_sections argument - run prompts either chunk by chunk (multiple sections at once) or section by section\n",
    "        process_func = process_chunk\n",
    "        if individual_sections: process_func = process_chunks_individual_sections\n",
    "        # try:\n",
    "        if 1:\n",
    "          process_func(content_type,\n",
    "                        index_chunk,\n",
    "                        chunk,\n",
    "                        output_dict,\n",
    "                        index_req,\n",
    "                        prompt,\n",
    "                        systemprompt,\n",
    "                        citation_prompt,\n",
    "                        templatename,\n",
    "                        df_control,\n",
    "                        df_results,\n",
    "                        df_errors,\n",
    "                        df_validation,\n",
    "                        fsd_lookup,\n",
    "                        bpd_lookup,\n",
    "                        transcripts_lookup,\n",
    "                        images_lookup,\n",
    "                        knowledge_base_docs,\n",
    "                        temperature,\n",
    "                        verbose,\n",
    "                        validation,\n",
    "                        backup_strict,\n",
    "                        log_id_doc)\n",
    "        # except Exception as err:\n",
    "        #   raise Exception(\"Error in populating chunk/section. Traceback: \" + str(err)) # will be handled in upper-level error handling -> skip to next document\n",
    "\n",
    "  ## Write document\n",
    "  docwriteback = write_back_to_document(templatedict[templatename]['docs'], output_dict, templatedict[templatename]['originalpositions'], verbose=verbose)\n",
    "  out_file='OGE_FSD_'+templatename.strip('OGE_Functional Specification Document').strip('.docx').strip('Template__Approved').strip('_').strip()+'-'+row['RICEFW ID']+'_'+row['RICEFW Name'].replace('/',',')+'_'+datetime.now().strftime('%Y-%m-%d_%H_%M_%S')+'.docx'\n",
    "  file_path='/tmp/SAP/'+out_file\n",
    "  log(f\"[{log_id_doc}] Writing file to workbench ('{file_path}') ...\")\n",
    "  docwriteback.save(file_path)\n",
    "  db_ws.CopyFileToWorkbench(filename=out_file, DatabricksFolder=\"file:/tmp/SAP/\")\n",
    "  log(f\"[{log_id_doc}] Writing file to workbench ('{file_path}') ... done\", color=\"green\")\n",
    "  df_control.loc[index_req, \"Outfile\"] = out_file\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28d18a94-b778-447f-8a16-ee3f61fb5c79",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Chunk level loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c421ea11-727d-4444-8c89-bc782ad9d17e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tiktoken\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "def num_tokens_from_messages(messages, model=\"gpt-4\"):\n",
    "    \"\"\"Return the number of tokens used by a list of messages.\"\"\"\n",
    "    try:\n",
    "        encoding = tiktoken.encoding_for_model(model)\n",
    "    except KeyError:\n",
    "        print(\"Warning: model not found. Using cl100k_base encoding.\")\n",
    "        encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    if model in {\n",
    "        \"gpt-3.5-turbo-0613\",\n",
    "        \"gpt-3.5-turbo-16k-0613\",\n",
    "        \"gpt-4-0314\",\n",
    "        \"gpt-4-32k-0314\",\n",
    "        \"gpt-4-0613\",\n",
    "        \"gpt-4-32k-0613\",\n",
    "        }:\n",
    "        tokens_per_message = 3\n",
    "        tokens_per_name = 1\n",
    "    elif model == \"gpt-3.5-turbo-0301\":\n",
    "        tokens_per_message = 4  # every message follows <|start|>{role/name}\\n{content}<|end|>\\n\n",
    "        tokens_per_name = -1  # if there's a name, the role is omitted\n",
    "    elif \"gpt-3.5-turbo\" in model:\n",
    "        print(\"Warning: gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\")\n",
    "        return num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0613\")\n",
    "    elif \"gpt-4\" in model:\n",
    "        print(\"Warning: gpt-4 may update over time. Returning num tokens assuming gpt-4-0613.\")\n",
    "        return num_tokens_from_messages(messages, model=\"gpt-4-0613\")\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            f\"\"\"num_tokens_from_messages() is not implemented for model {model}. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.\"\"\"\n",
    "        )\n",
    "    num_tokens = 0\n",
    "    num_tokens += len(encoding.encode(messages))\n",
    "\n",
    "    num_tokens += 3  # every reply is primed with <|start|>assistant<|message|>\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13b18315-76a7-4186-96f3-9b73a59d3d3b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def process_chunk(content_type,\n",
    "                  index_chunk,\n",
    "                  chunk,\n",
    "                  output_dict,\n",
    "                  index_req,\n",
    "                  #row,\n",
    "                  prompt,\n",
    "                  systemprompt,\n",
    "                  citation_prompt,\n",
    "                  templatename,\n",
    "                  df_control,\n",
    "                  df_results,\n",
    "                  df_errors,\n",
    "                  df_validation,\n",
    "                  fsd_lookup,\n",
    "                  bpd_lookup,\n",
    "                  transcripts_lookup,\n",
    "                  images_lookup,\n",
    "                  knowledge_base_docs,\n",
    "                  temperature,\n",
    "                  verbose,\n",
    "                  validation,\n",
    "                  backup_strict,\n",
    "                  log_id_doc):\n",
    "  \n",
    "  # print(content_type)\n",
    "  # print()\n",
    "  # print(index_chunk)\n",
    "  # print()\n",
    "  # print(chunk)\n",
    "  # print()\n",
    "  # print(output_dict)\n",
    "  # print()\n",
    "  # print(index_req)\n",
    "  # print()\n",
    "  # print(prompt)\n",
    "  # print()\n",
    "  # print(systemprompt)\n",
    "  # print()\n",
    "  # print(citation_prompt)\n",
    "  # print()\n",
    "  # print(templatename)\n",
    "  # print()\n",
    "  # print(df_control)\n",
    "  # print()\n",
    "  # print(df_results)\n",
    "  # print()\n",
    "  # print(df_errors)\n",
    "  # print()\n",
    "  # print(df_validation)\n",
    "  # print()\n",
    "  # print(fsd_lookup)\n",
    "  # print()\n",
    "  # print(bpd_lookup)\n",
    "  # print()\n",
    "  # print(transcripts_lookup)\n",
    "  # print()\n",
    "  # print(images_lookup)\n",
    "  # print()\n",
    "  # print(knowledge_base_docs)\n",
    "  # print()\n",
    "  # print(temperature)\n",
    "  # print()\n",
    "  # print(verbose)\n",
    "  # print()\n",
    "  # print(validation)\n",
    "  # print()\n",
    "  # print(backup_strict)\n",
    "  # print()\n",
    "  # print(log_id_doc)\n",
    "  # raise Exception(\"skipped chunk processing in debug mode. Edit cmd 6 in SAP_FDD_CORE to turn off debug mode.\") # DEBUG\n",
    "\n",
    "  # restartability idea - check if replacement texts for chunk already populated, if so, skip to next chunk\n",
    "  # this way, if the run gets interrupted, it can just be restarted\n",
    "  if content_type == \"paragraphs\":\n",
    "    if df_control.loc[index_req, \"LastChunk_contenttype\"] == \"tables\":\n",
    "      # if the paragraphs are done already (pointer is at tables), skip all paragraphs\n",
    "      log(f\"[{log_id_doc}] {content_type} chunk {index_chunk+1}/{len(output_dict[content_type]['chunks'])} already populated. skipping to next chunk.\")\n",
    "      return\n",
    "    elif df_control.loc[index_req, \"LastChunk_contenttype\"] == \"paragraphs\":\n",
    "      # if the paragraphs are started, but not done (pointer is at paragraphs)\n",
    "      if df_control.loc[index_req, \"LastChunk_index\"] >= index_chunk:\n",
    "        #  if the last written chunk number is higher than the current, skip current\n",
    "        log(f\"[{log_id_doc}] {content_type} chunk {index_chunk+1}/{len(output_dict[content_type]['chunks'])} already populated. skipping to next chunk.\")\n",
    "        return\n",
    "      # else: #  if the last written chunk number is lower than the current, go on and populate for current\n",
    "  elif content_type == \"tables\":\n",
    "    if df_control.loc[index_req, \"LastChunk_contenttype\"] == \"tables\":\n",
    "      # if the tables are started, but not done (pointer is at tables)\n",
    "      if df_control.loc[index_req, \"LastChunk_index\"] >= index_chunk:\n",
    "        #  if the last written chunk number is higher than the current, skip current\n",
    "        log(f\"[{log_id_doc}] {content_type} chunk {index_chunk+1}/{len(output_dict[content_type]['chunks'])} already populated. skipping to next chunk.\")\n",
    "        return\n",
    "      # else: #  if the last written chunk number is lower than the current, go on and populate for current\n",
    "    # else: if the pointer is still at paragraphs, go on and populate (happens only for first table after paragraphs are done)\n",
    "  # else: nothing populated yet (pointer is blank), go on and populate first paragraph & chunk\n",
    "\n",
    "  if df_control.loc[index_req, \"LastChunk_contenttype\"] == content_type and df_control.loc[index_req, \"LastChunk_index\"] >= index_chunk:\n",
    "    log(f\"[{log_id_doc}] {content_type} chunk {index_chunk+1}/{len(output_dict[content_type]['chunks'])} already populated. skipping to next chunk.\")\n",
    "    return  \n",
    "  \n",
    "  log(f\"[{log_id_doc}] Processing {content_type} chunk {index_chunk+1}/{len(output_dict[content_type]['chunks'])} ... \")\n",
    "  curr_prompt = prompt\\\n",
    "    .replace(\"{requirement}\", df_control.loc[index_req, \"Requirement Cleansed\"])\\\n",
    "    .replace(\"{jsontemplate}\", json.dumps(chunk))\\\n",
    "    .replace(\"{RICEFWType}\", df_control.loc[index_req, \"RICEFW Type\"])\\\n",
    "    .replace(\"{RICEFWID}\", df_control.loc[index_req, \"RICEFW ID\"])\\\n",
    "    .replace(\"{RICEFWName}\", df_control.loc[index_req, \"RICEFW Name\"])\\\n",
    "    .replace(\"{requirement_detailed_description}\",df_control.loc[index_req, \"Detailed Description\"])\\\n",
    "    .replace(\"{citation_prompt}\",citation_prompt)\n",
    "\n",
    "  if transcripts_lookup != None:\n",
    "    curr_prompt = curr_prompt.replace(\"{transcripts_lookup}\", f\"\"\"\\n\\nInfo on requirement from workshop transcripts: \\n```\\n{transcripts_lookup}\\n```\\n\"\"\")\n",
    "  else: curr_prompt = curr_prompt.replace(\"{transcripts_lookup}\", \"\")\n",
    "\n",
    "  if fsd_lookup != None:\n",
    "    curr_prompt = curr_prompt.replace(\"{fsd_lookup}\", f\"\"\"\\n\\nInfo on requirement from FSDs for other projects (Use for reference only and do not copy as is, don't refer to specific people, entity or asset names): \\n```\\n{fsd_lookup}\\n```\\n\"\"\")\n",
    "  else: curr_prompt = curr_prompt.replace(\"{fsd_lookup}\", \"\")\n",
    "\n",
    "  if bpd_lookup != None:\n",
    "    curr_prompt = curr_prompt.replace(\"{bpd_lookup}\", f\"\"\"\\n\\nInfo on requirement from business process docs (Use for reference only and do not copy as is, don't refer to specific people, entity or asset names): \\n```\\n{bpd_lookup}\\n```\\n\"\"\")\n",
    "  else: curr_prompt = curr_prompt.replace(\"{bpd_lookup}\", \"\")\n",
    "\n",
    "  if knowledge_base_docs != None:\n",
    "    kb_docs_lookup = knowledge_base_docs[templatename][\"placeholders\"][content_type][\"chunks\"][index_chunk]\n",
    "    curr_prompt = curr_prompt.replace(\"{knowledge_base_docs}\", f\"\"\"\\n\\nExamples of 'what good looks like' from FSDs for other projects, not directly related to this requirement (Use for reference only and do not copy as is, don't refer to specific people, entity or asset names): \\n```\\n{kb_docs_lookup}\\n```\\n\"\"\")\n",
    "  else: curr_prompt = curr_prompt.replace(\"{knowledge_base_docs}\", \"\")\n",
    "\n",
    "  if verbose: print(curr_prompt)\n",
    "  print('*'*20 + \"Sending 3.5 turbo request\")\n",
    "  print(\"Token count:\")\n",
    "  print(num_tokens_from_messages(curr_prompt) + num_tokens_from_messages(systemprompt))\n",
    "\n",
    "  # response = gpt4(prompt=curr_prompt, context=systemprompt, temperature=temperature, max_tokens=6000, large=True, tries=3).replace('\\\\\\\\','/').replace('}],','},')\n",
    "  response = gpt35(prompt=curr_prompt, context=systemprompt, temperature=temperature, max_tokens=10000, tries=3)\n",
    "  \n",
    "  if validation: \n",
    "    # print(\"writing prompt to validation df\") # DEBUG\n",
    "    val_row = {'RICEFW ID': df_control.loc[index_req, \"RICEFW ID\"],\n",
    "              'RICEFW Name': df_control.loc[index_req, \"RICEFW Name\"],\n",
    "              'Chunk Numb': index_chunk + 1,\n",
    "              'Prompt': curr_prompt,\n",
    "              'Response': response}\n",
    "    df_validation.loc[len(df_validation.index)] = val_row\n",
    "\n",
    "  fix_json_system_prompt='You are an expert at fixing JSONs'\n",
    "  fix_json_user_prompt='''Fix the following JSON so that it can be successfully loaded by json.loads, response should be only the fixed JSON:\n",
    "  {error_json}'''\n",
    "\n",
    "  try:\n",
    "    response_json = json.loads(response, strict=False)\n",
    "    print(' response_json:')\n",
    "    print(response_json)\n",
    "  except:\n",
    "    print(\"ERROR - Error in populating requirement. GPT response could not be parsed as JSON. Asking GPT to correct response...\")\n",
    "    response=gpt35(prompt=fix_json_user_prompt.replace('{error_json}',response), context=fix_json_system_prompt, temperature=0, max_tokens=10000, large=True, tries=3)\n",
    "    try:\n",
    "      response_json = json.loads(response, strict=False)\n",
    "    except Exception as err:\n",
    "      # GPT returned ill-formatted JSON in its response -> Skip to next requirement\n",
    "      log(f\"[{log_id_doc}] ERROR - Error in populating requirement. GPT response could not be parsed as JSON. This event has been noted in the error table.\", color=\"red\")\n",
    "      print(\"Traceback:\")\n",
    "      print(err)\n",
    "      if verbose:\n",
    "        print(\"Full GPT Prompt response:\")\n",
    "        print(response)\n",
    "      # Append incomplete response to error capturing dataframe\n",
    "      err_row = {'RICEFW ID': df_control.loc[index_req, \"RICEFW ID\"],\n",
    "                  'RICEFW Name': df_control.loc[index_req, \"RICEFW Name\"],\n",
    "                  'LastChunk_contenttype': content_type,\n",
    "                  'LastChunk_index': index_chunk,\n",
    "                  'response': response}\n",
    "      df_errors.loc[len(df_errors.index)] = err_row\n",
    "      raise Exception(\"Invalid JSON response\") # will jump into upper-level try-block, thus skipping to next requirement\n",
    "\n",
    "  # check if all elements contain all required JSON attributes ('section_header', placeholder_text', 'replacement_text')\n",
    "  # this is basically a big try - except\n",
    "  for elem in response_json:\n",
    "    elem_keys = list(elem.keys())\n",
    "    # print(elem_keys) # DEBUG\n",
    "    if not (\"section_header\" in elem_keys and \"placeholder_text\" in elem_keys and \"replacement_text\" in elem_keys):\n",
    "      # GPT returned ill-formatted JSON in its response -> Skip to next requirement\n",
    "      log(f\"[{log_id_doc}] ERROR - Error in populating requirement. GPT response is valid JSON, but does not contain all required fields. This event has been noted in the error table.\", color=\"red\")\n",
    "      if verbose:\n",
    "        print(\"Full GPT Prompt response:\")\n",
    "        print(response)\n",
    "      # Append incomplete response to error capturing dataframe\n",
    "      err_row = {'RICEFW ID': df_control.loc[index_req, \"RICEFW ID\"],\n",
    "                  'RICEFW Name': df_control.loc[index_req, \"RICEFW Name\"],\n",
    "                  'LastChunk_contenttype': content_type,\n",
    "                  'LastChunk_index': index_chunk,\n",
    "                  'response': response}\n",
    "      df_errors.loc[len(df_errors.index)] = err_row\n",
    "      raise Exception(\"Valid, but incomplete JSON response\") # will jump into upper-level try-block, thus skipping to next requirement   \n",
    "  \n",
    "  # if no exceptions above (i.e. the response is valid and complete) - write response to result\n",
    "  output_dict[content_type][\"chunks\"][index_chunk] = response_json\n",
    "  \n",
    "  # write back to control table\n",
    "  df_results.loc[index_req, \"JSON\"] = json.dumps(output_dict)\n",
    "  df_control.loc[index_req, \"LastChunk_contenttype\"] = content_type\n",
    "  df_control.loc[index_req, \"LastChunk_index\"] = index_chunk\n",
    "  if backup_strict: backup(df_control)\n",
    "\n",
    "  log(f\"[{log_id_doc}] Processing {content_type} chunk {index_chunk+1}/{len(output_dict[content_type]['chunks'])} ... done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70dc5d9f-4107-426d-941e-d9a50b00dc7d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def process_chunks_individual_sections(content_type,\n",
    "                  index_chunk,\n",
    "                  chunk,\n",
    "                  output_dict,\n",
    "                  index_req,\n",
    "                  prompt,\n",
    "                  systemprompt,\n",
    "                  citation_prompt,\n",
    "                  templatename,\n",
    "                  df_control,\n",
    "                  df_results,\n",
    "                  df_errors,\n",
    "                  fsd_lookup,\n",
    "                  bpd_lookup,\n",
    "                  transcripts_lookup,\n",
    "                  knowledge_base_docs,\n",
    "                  temperature,\n",
    "                  verbose,\n",
    "                  backup_strict,\n",
    "                  log_id_doc):\n",
    "  \n",
    "  # raise Exception(\"skipped chunk processing in debug mode. Edit cmd 6 in SAP_FDD_CORE to turn off debug mode.\") # DEBUG\n",
    "\n",
    "  prompt_individual_sections = \"\"\"\n",
    "  ### Start of Requirement Info\n",
    "  Requirement: '{requirement}'\n",
    "  RICEFW Type='{RICEFWType}'\n",
    "  RICEFW ID='{RICEFWID}'\n",
    "  RICEFW Name='{RICEFWName}'\n",
    "  Requirement detailed description: \n",
    "  ```\n",
    "  {requirement_detailed_description}\n",
    "  ```\n",
    "  {transcripts_lookup}\n",
    "  {bpd_lookup}\n",
    "  {fsd_lookup}\n",
    "  {knowledge_base_docs}\n",
    "  ### End of Requirement Info\n",
    "\n",
    "  Based on the requirement info above, your task is to fill the placeholder '{placeholder_text}' for section header '{section_header}' with content. Your response should be only the generated content in plain text\n",
    "  \n",
    "  Your generated content:\n",
    "  \"\"\"\n",
    "\n",
    "  #, should be lengthy paragraphs instead of one liners, use bullet points where necessary, customize based on input requirement {citation_prompt}, always have your own perspective, back it up with detailed explanations and scenarios/examples, also refer to the section_header for additional context.\n",
    "\n",
    "  for index_section, section in enumerate(chunk):\n",
    "\n",
    "    # # restartability idea - check if replacement texts for chunk already populated, if so, skip to next chunk\n",
    "    # # this way, if the run gets interrupted, it can just be restarted\n",
    "    # if content_type == \"paragraphs\":\n",
    "    #   if df_control.loc[index_req, \"LastChunk_contenttype\"] == \"tables\":\n",
    "    #     # if the paragraphs are done already (pointer is at tables), skip all paragraphs\n",
    "    #     log(f\"[{log_id_doc}] {content_type} chunk {index_chunk+1}/{len(output_dict[content_type]['chunks'])} already populated. skipping to next chunk.\")\n",
    "    #     return\n",
    "    #   elif df_control.loc[index_req, \"LastChunk_contenttype\"] == \"paragraphs\":\n",
    "    #     # if the paragraphs are started, but not done (pointer is at paragraphs)\n",
    "    #     if df_control.loc[index_req, \"LastChunk_index\"] >= index_chunk:\n",
    "    #       #  if the last written chunk number is higher than the current, skip current\n",
    "    #       log(f\"[{log_id_doc}] {content_type} chunk {index_chunk+1}/{len(output_dict[content_type]['chunks'])} already populated. skipping to next chunk.\")\n",
    "    #       return\n",
    "    #     # else: #  if the last written chunk number is lower than the current, go on and populate for current\n",
    "    # elif content_type == \"tables\":\n",
    "    #   if df_control.loc[index_req, \"LastChunk_contenttype\"] == \"tables\":\n",
    "    #     # if the tables are started, but not done (pointer is at tables)\n",
    "    #     if df_control.loc[index_req, \"LastChunk_index\"] >= index_chunk:\n",
    "    #       #  if the last written chunk number is higher than the current, skip current\n",
    "    #       log(f\"[{log_id_doc}] {content_type} chunk {index_chunk+1}/{len(output_dict[content_type]['chunks'])} already populated. skipping to next chunk.\")\n",
    "    #       return\n",
    "    #     # else: #  if the last written chunk number is lower than the current, go on and populate for current\n",
    "    #   # else: if the pointer is still at paragraphs, go on and populate (happens only for first table after paragraphs are done)\n",
    "    # # else: nothing populated yet (pointer is blank), go on and populate first paragraph & chunk\n",
    "\n",
    "    # if df_control.loc[index_req, \"LastChunk_contenttype\"] == content_type and df_control.loc[index_req, \"LastChunk_index\"] >= index_chunk:\n",
    "    #   log(f\"[{log_id_doc}] {content_type} chunk {index_chunk+1}/{len(output_dict[content_type]['chunks'])} already populated. skipping to next chunk.\")\n",
    "    #   return\n",
    "\n",
    "    log(f\"[{log_id_doc}] Processing {content_type} chunk {index_chunk+1}/{len(output_dict[content_type]['chunks'])} section {index_section+1}/{len(chunk)} ... \")\n",
    "    curr_prompt = prompt_individual_sections\\\n",
    "      .replace(\"{requirement}\", df_control.loc[index_req, \"Requirement Cleansed\"])\\\n",
    "      .replace(\"{placeholder_text}\", json.dumps(section[\"placeholder_text\"]))\\\n",
    "      .replace(\"{section_header}\", json.dumps(section[\"section_header\"]))\\\n",
    "      .replace(\"{RICEFWType}\", df_control.loc[index_req, \"RICEFW Type\"])\\\n",
    "      .replace(\"{RICEFWID}\", df_control.loc[index_req, \"RICEFW ID\"])\\\n",
    "      .replace(\"{RICEFWName}\", df_control.loc[index_req, \"RICEFW Name\"])\\\n",
    "      .replace(\"{requirement_detailed_description}\",df_control.loc[index_req, \"Detailed Description\"])\\\n",
    "      .replace(\"{citation_prompt}\",citation_prompt)\n",
    "\n",
    "    if transcripts_lookup != None:\n",
    "      curr_prompt = curr_prompt.replace(\"{transcripts_lookup}\", f\"\"\"\\n\\nInfo on requirement from workshop transcripts: \\n```\\n{transcripts_lookup}\\n```\\n\"\"\")\n",
    "    else: curr_prompt = curr_prompt.replace(\"{transcripts_lookup}\", \"\")\n",
    "\n",
    "    if fsd_lookup != None:\n",
    "      curr_prompt = curr_prompt.replace(\"{fsd_lookup}\", f\"\"\"\\n\\nInfo on requirement from FSDs for other projects (Use for reference only and do not copy as is, don't refer to specific people, entity or asset names): \\n```\\n{fsd_lookup}\\n```\\n\"\"\")\n",
    "    else: curr_prompt = curr_prompt.replace(\"{fsd_lookup}\", \"\")\n",
    "\n",
    "    if knowledge_base_docs != None:\n",
    "      kb_docs_lookup = knowledge_base_docs[templatename][\"placeholders\"][content_type][\"chunks\"][index_chunk]\n",
    "      curr_prompt = curr_prompt.replace(\"{knowledge_base_docs}\", f\"\"\"\\n\\nExamples of 'what good looks like' from FSDs for other projects, not directly related to this requirement (Use for reference only and do not copy as is, don't refer to specific people, entity or asset names): \\n```\\n{kb_docs_lookup}\\n```\\n\"\"\")\n",
    "    else: curr_prompt = curr_prompt.replace(\"{knowledge_base_docs}\", \"\")\n",
    "\n",
    "    if verbose: print(curr_prompt)\n",
    "\n",
    "    # response = gpt4(prompt=curr_prompt, context=systemprompt, temperature=temperature, max_tokens=20000, large=True, tries=3)\n",
    "    response = gpt35(prompt=curr_prompt, context=systemprompt, temperature=temperature, max_tokens=6000, tries=3)\n",
    "    \n",
    "    try:\n",
    "      output_dict[content_type][\"chunks\"][index_chunk][index_section][\"replacement_text\"] = response\n",
    "    except Exception as err:\n",
    "      # GPT returned ill-formatted JSON in its response -> Skip to next requirement\n",
    "      log(f\"[{log_id_doc}] ERROR - Error in populating requirement. GPT response could not be parsed as JSON. This event has been noted in the error table.\", color=\"red\")\n",
    "      print(\"Traceback:\")\n",
    "      print(err)\n",
    "      if verbose:\n",
    "        print(\"Full GPT Prompt response:\")\n",
    "        print(response)\n",
    "      # Append incomplete response to error capturing dataframe\n",
    "      err_row = {'RICEFW ID': df_control.loc[index_req, \"RICEFW ID\"],\n",
    "                  'RICEFW Name': df_control.loc[index_req, \"RICEFW Name\"],\n",
    "                  'LastChunk_contenttype': content_type,\n",
    "                  'LastChunk_index': index_chunk,\n",
    "                  'response': response}\n",
    "      df_errors.loc[len(df_errors.index)] = err_row\n",
    "      raise Exception(\"Invalid JSON response\") # will jump into upper-level try-block, thus skipping to next requirement   \n",
    "    \n",
    "    # write back to control table\n",
    "    df_results.loc[index_req, \"JSON\"] = json.dumps(output_dict)\n",
    "    df_control.loc[index_req, \"LastChunk_contenttype\"] = content_type\n",
    "    df_control.loc[index_req, \"LastChunk_index\"] = index_chunk\n",
    "    if backup_strict: backup(df_control)\n",
    "\n",
    "    log(f\"[{log_id_doc}] Processing {content_type} chunk {index_chunk+1}/{len(output_dict[content_type]['chunks'])} section {index_section+1}/{len(chunk)} ... done.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "SAP_FDD_Core",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
